[["index.html", "IPW and AIPW 1 Work in Progress", " IPW and AIPW Vinish Shrestha 2025-01-08 1 Work in Progress This is a work in progress. "],["causal-inference-an-introduction.html", "2 Causal Inference: An Introduction", " 2 Causal Inference: An Introduction “Correlation is not causality” is one of the most frequently used lines in social science. In a lab experiment, a researcher can perform controlled experiments to determine whether A causes B by controlling for confounders. However, the complexities and interrelations of human behavior create a setting starkly different from the controlled environment of a lab, making things much more convoluted. Causal inference, therefore, can be seen as a process to determine whether A causes B in both lab settings and out-of-lab scenarios. A simple example. Say, we are interested in evaluating the effects of a tutoring program on exam scores for an introductory course. To begin, in this simple example, we assume that the treatment is (completely) randomly assigned. The class is randomly divided into two groups: one group receives the treatment (treatment group) and the other group does not receive the treatment (control group). Proper randomization means that each individual has an equal probability of receiving the treatment or not receiving it. This approach with an arbitrarily high probability ensures balance in both observed and unobserved factors as the sample size grows such that any differences in outcomes between the treatment and control groups can be attributed to the treatment itself, rather than to pre-existing differences between the groups.1 Balance here is defined as an instance when all pre-treatment covariates between the treatment and control groups are similar. If this is attained then it increases confidence that the treatment and the control units are comparable. Set up. We use \\(W\\) to denote the treatment status such that \\(W_i \\in \\{0, \\; 1\\}\\), \\(Y_i\\) is the exam score following the treatment assignment, and \\(X_i\\) are the covariates (e.g., gender, race). The subscript \\(i\\) indicates an individual or unit of observation. Of course, balance is not guranteed and in such cases one should think hard whether differences in covariates matter, and if they do, adjustment should be applied.↩︎ "],["potential-outcome-framework-neyman-rubin-causal-model.html", "2.1 Potential Outcome Framework: Neyman-Rubin Causal Model", " 2.1 Potential Outcome Framework: Neyman-Rubin Causal Model We are going to use the potential outcome framework to describe the impacts of the treatment following the Neyman-Rubin causal model (Splawa-Neyman, Dabrowska, and Speed 1923 [1990]; Rubin 1974). Define \\(Y_i(0)\\) and \\(Y_i(1)\\) as the potential outcomes for an individual \\(i\\) in the case of treatment and without treatment, respectively. The potential outcomes are not realized yet. As such it is wrong to say that \\(Y_{i}(0) = Y_i\\). Let’s spend some time discussing various formats of the potential outcome in relation to what is observed versus what is not. \\([Y_{i}(0)|W_i = 0].\\) Here, the expression in the bracket is read as the outcome of an unit \\(i\\) in the no-treatment state conditional upon \\(i\\) actually not receiving the treatment. This is an observed outcome. \\([Y_{i}(0)|W_i = 1].\\) Here, the expression is asking for what the outcome of an unit \\(i\\) who received the treatment \\((W_i = 1)\\) would be in absence of the treatment. This is not observed and is termed as the counterfactual. The same goes with the potential outcome \\(Y_{i}(1)\\) – the outcome if \\(i\\) were to be treated. The observed variable, \\(Y_i\\), can be written as a function of the potential outcomes as follows: \\[\\begin{equation} Y_i = W \\times Y_i(1) + (1-W)\\times Y_i(0) \\end{equation}\\] The fundamental problem is that one cannot observe both \\(Y_i(0)\\) and \\(Y_i(1)\\) at the same time. As such, the causal inference through the lens of Neyman-Rubin causal framework can be seen as the missing data problem. If one has the data for \\(Y_i(1)\\) then the \\(Y_i(0)\\) counterpart is missing and vice-versa. Much of causal inference is finding ways to deal with the missing-data problem. The independence assumption allows us to proceed further with causality. Formally, a complete random assignment of treatment means: \\(W_i \\perp Y_i(0), Y_i(1)\\). This states that the treatment assignment is independent of potential outcomes. Quite literally, this means that the treatment assignment is not related to the potential outcome. In other words, the treatment assignment is completely random (probability of being treated is 0.5 in the case of binary treatment). The independence assumption also states that the treatment assignment is independent of any covariates \\(X_i\\). In our particular example, this means that the probability of receiving the treatment is the same for different groups defined by these covariates, such as gender and race. Specifically, females are equally likely to get treated compared to males, and Blacks are equally likely to be treated compared to Whites. Within both the treatment and control groups, it is highly likely that the proportion of Blacks and Whites, as well as males and females, will be similar – an attribute known as balance. The independence assumption is one of the necessary assumptions to proceed further but it is not sufficient. Additional two assumptions are needed to proceed ahead: overlap and Stable Unit Treatment Value Assumption (SUTVA). The overlap assumption states that observations in both the treatment and control groups fall within the common support. For instance, this assumption is violated if the treatment group consist of all females and the control group consist of all males as one would not be able to attain balance in covariates. The independence and overlap assumption together constitute a property known as stong ignorability of assignment, which is necessary for the identification of the treatment effect. The SUTVA assumption is the no interference assumption defining that the treatment status of one unit should not affect the potential outcome for other units. In our example, tutoring treatment for a unit in the treatment group should not change the potential outcome for other units. This assumption breaks down if there is a spillover effect, for example, if the a student in the treatment group helps her friend in the control group. References "],["average-treatment-effect-ate.html", "2.2 Average treatment effect (ATE)", " 2.2 Average treatment effect (ATE) Our target is to estimate the effects of the treatment. For a brief moment, let’s assume the presence of a parallel universe that includes Alia, Ryan, Shrey, Samaira, and Rakshya in the course. In one universe (actual universe) the treatment for these individuals are randomly allocated: \\(W_{Alia} = 1\\), \\(W_{Ryan} = 0\\), \\(W_{Shrey} = 0\\), \\(W_{Samaira} = 1\\), \\(W_{Rakshya} = 0\\). In the other (parallel) universe, everything is similar to the actual universe except that the treatment status is exactly opposite. In this case, individual specific treatment effect can be estimated by taking the difference in individual specific outcomes across two universes. For example, the treatment effect for Alia is \\(Y_{Alia}(1) - Y_{Alia}(0).\\) This is feasible since a perfect counterfactual is available for all the units given the parallel universe. The average of such individual treatment effect gives the average treatment effect, ATE. The target is to estimate average treatment effect (ATE), which is defined as: \\[\\begin{equation} ATE = E(Y_i(1)) - E(Y_i(0)) \\end{equation}\\] \\(Y_i(1)\\) denotes the outcome for an unit \\(i\\) in presence of treatment, whereas \\(Y_i(0)\\) is the realization for the same unit \\(i\\) in absence of the treatment. As we know, it is impossible to measure the unit \\(i\\) in two different states (with and without treatment). A major difficulty is that one cannot observe units simultaneously with and without treatment in reality. This means that the perfect counterfactual does not really exist. This again emphasizes causal inference as a missing data problem – when estimating the treatment effect of an unit \\(i\\), \\(Y_i(0)\\) is not observed if \\(Y_i(1)\\) is and vice-versa. This unfortunately does not allow us to estimate individualized treatment effect. The best we can do (as of yet) is use the independence assumption as well as overlap assumption together and evalute ATE. Note that the independence condition, $ W_i Y_i(0), ; Y_i(1)$, gives: \\(E(Y_i(0)|W_i = 1) = E(Y_i(0)|W_i = 0)\\). The term, \\(E(Y_i(0))\\), in ATE equation is replaced by \\(E(Y_i|W_i = 0)\\). In the case of a pure randomized experiment, the ATE is given as: \\[\\begin{equation} ATE = E(Y_i | W_i = 1) - E(Y_i | W_i = 0) \\end{equation}\\] ATE evaluates treatment effect for the whole population by comparing the treated units to the control units. "],["rct.html", "2.3 RCT", " 2.3 RCT Randomized Controlled Trials (RCTs) are the cornerstone of causal inference and are often referred to as the gold standard. The quality of non-experimental studies is frequently assessed by comparing how closely the observational setting approximates an RCT. In an RCT, the Average Treatment Effect (ATE) is identified through the randomization of treatment assignment. This process ensures that the treatment and control groups are comparable, making RCTs a straightforward yet immensely powerful tool for establishing causal relationships. In a simple RCT setting the treatment is binary – the units are either assigned to the treatment group \\((W_i = 0)\\) or the control group \\((W_i = 1)\\). The implicit assumption in this design is that each unit has an equal probability of being treated. The treatment assignment for the RCT setting can be attained using a Bernoulli process, where each unit has an independent probability \\(\\pi\\) of receiving treatment. Specifically, each unit is assigned to the treatment group with probability \\(\\pi\\) and to the control group with probability \\(1 - \\pi\\). # a bernoulli process of treatment assignment library(ggplot2) fun_treat_assign &lt;- function(N, prob, treat.type){ treatment &lt;- rbinom(N, size = 1, p = prob) dat &lt;- data.frame(treatment = treatment, type = treat.type) return(dat) } # p = 0.5 for each unit dat1 &lt;- fun_treat_assign(N = 10000, prob = 0.5, treat.type = &quot;p = 0.5&quot;) # p = 0.3 for each unit dat2 &lt;- fun_treat_assign(N = 10000, prob = 0.2, treat.type = &quot;p = 0.2&quot;) dat.assign &lt;- rbind(dat1, dat2) # plot ggplot(dat.assign, aes(x = treatment)) + geom_histogram(fill= &quot;skyblue&quot;, color = &quot;black&quot;) + facet_wrap(~ type) + theme_minimal() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. A practical example of this is an unbiased coin toss used to determine treatment assignment. In this case, a head could correspond to the treatment group (e.g., \\(W_i = 1\\)), and a tail to the control group (e.g., \\(W_i = 0\\)). This method exemplifies Bernoulli-randomization, where the assignment is determined by a random process, ensuring that each unit has an equal probability of being assigned to either group. In an RCT setting, the difference-in-means estimator is given as: \\[\\begin{equation} \\hat{\\tau} = \\frac{1}{N_t}\\sum_{W_i =1} Y_i - \\frac{1}{N_c}\\sum_{W_i =0} Y_i \\end{equation}\\] The difference-in-mean estimator is unbiased and consistent for the average treatment effect. "],["average-treatment-effect-on-the-treated-att.html", "2.4 Average treatment effect on the treated (ATT)", " 2.4 Average treatment effect on the treated (ATT) The average treatment effect on the treated is concerned with the evaluation of treatment effects for only those units that are treated. Formally, it is defined as: \\[\\begin{equation} ATT = E(Y_i(1) - Y_i(0) | W_i = 1) \\end{equation}\\] ATE is only concerned with a subset of the population who received the treatment, \\(E[.|W_i = 1]\\). Here, ATT is comparing outcomes among the treated units in presence of the treatment versus what the outcomes would have been in absence of the treatment only for units receiving the treatment. Hence, only one segment of the counterfactual (potential outcome) is required. In our example, the counterfactual for Alia and Samaira would allow estimation of ATT, whereas ATE requires counterfactual for everyone. The independence condition states that on average the potential outcomes for the treated group in absence of the treatment would be similar to the average outcome for the control group, i.e. \\(E(Y_i(0)|W_i = 1) = E(Y_i(0)|W_i = 0)\\). This allows re-writing ATT as the following: \\[\\begin{align} ATT = E\\{E(Y_i | W_i = 1) - E(Y_i | W_i = 0) | W_i = 1\\} \\\\ ATT = E(Y_i | W_i = 1) - E(Y_i | W_i = 0) \\end{align}\\] The second line follows from the independence assumption which allows this: \\(E\\{E(Y_i | W_i = 0) | W_i = 1\\} = E(Y_i | W_i = 0).\\) Under the independence assumption this means that we can estimate ATT by substrating the averages of exam score across the treated and control units. In purely randomized experiments, if there is a perfect case of compliance, then the ATT will be similar to ATE. "],["an-estimation-example.html", "2.5 An estimation example", " 2.5 An estimation example # create a function to estimate the treatment effects fun_ATE &lt;- function(tau, N){ # @arg tau: true treatment effect # @arg N: sample size # Return tau_hat: estimate of the treatment effect gender &lt;- rbinom(N, size = 1, p = 0.5) race &lt;- rbinom(N, size = 1, p = 0.5) W &lt;- rbinom(N, size = 1, p = 0.5) Y &lt;- 50 + tau * W + gender * 5 + race * 10 + rnorm(n = N, mean = 5, sd = 5) tau_hat &lt;- mean(Y[which(W == 1)]) - mean(Y[which(W == 0)]) return(tau_hat) } # print treatment effect print(paste(&quot;the ATE estimate is: &quot;, fun_ATE(tau = 10, N = 2000))) ## [1] &quot;the ATE estimate is: 10.0179854369989&quot; # run 2000 replications to get a distribution of tau_hats reps &lt;- 2000 tau.hats &lt;- rep(0, reps) for(i in 1:reps){ tau.hats[i] &lt;- fun_ATE(tau = 10, N = 2000) } # histogram of tau hats hist(tau.hats, breaks = 30) # obtaining the standard error print(paste(&quot;the mean of tau hats : &quot;, mean(tau.hats))) ## [1] &quot;the mean of tau hats : 10.0081130728545&quot; print(paste(&quot;the standard error of tau hats : &quot;, sd(tau.hats))) ## [1] &quot;the standard error of tau hats : 0.333223640718024&quot; "],["unconfoundedness-assumption.html", "2.6 Unconfoundedness assumption", " 2.6 Unconfoundedness assumption Most of the time the treatment assignment may not be fully random but can be driven by some selective covariates. Referring to the tutoring example, it may be unethical to disallow someone in the control group who wants to attend the tutoring sessions. As such, tutoring sessions may be voluntarily held, where students can select whether to attend the session. Say, females and Blacks are more likely to attend the tutoring session and both of these variables are also likely to yield higher potential outcome. This means that females and Blacks are more likely to have higher exam score in absence of the treatment compared to males and Whites. It is easy to see that the treatment assignment is correlated with the potential outcomes and the independence assumption is violated. This is true in many cases of observational settings and even in randomized experiments. We require adjustments before being able to estimate treatment effects in such cases. If we understand the treatment mechanism fairly well then we can still proceed further to estimate the treatment effects. For example, suppose the treatment assignment is (voluntarily) more tilted towards females than males and Blacks than Whites. In this case, we would want to invoke unconfoundedness (conditional independence) assumption.2 Formally, this states that \\(Y_i(0), \\; Y_i(1) \\perp W_i | X_i\\). This means that conditional upon the covariates the treatment assignment is random. To estimate ATT one would want to first estimate ATT within each strata: \\(i)\\) female-Black, \\(ii)\\) female-White, \\(iii)\\) male-Black, and \\(iv)\\) male-White, and take a weighted average of the strata-specific ATEs by using the proportion of the sample in the given strata as weights. The conditional independence assumption means that within each strata treatment assignment is random. The following code first estimates the strata specific ATTs and then summarizes them using the weighted average. Note that the true treatment effect is 10. fun_ATE2 &lt;- function(N, tau){ # @arg tau: true treatment effect # @arg N: sample size # Return tau_hat: estimate of the treatment effect using conditional randomness assumption # Return tau_hat2: estimate of the treatment effect wrongly using unconditional independence assumption # Return reg_tau: estimate from conditioning using regression but from a misspecified model # create pseudo data gender &lt;- rbinom(N, size = 1, p = 0.5) race &lt;- rbinom(N, size = 1, p = 0.5) W &lt;- rbinom(N, size = 1, p = 0.2 + 0.4 * (gender &gt; 0) + 0.2 * (race &gt; 0)) Y &lt;- 40 + 10 * W + gender * 2 + race * 5 + 25 * race * gender + rnorm(n = N, mean = 5, sd = 5) # female-Blacks tau_hat1 &lt;- mean(Y[which(W == 1 &amp; gender == 1 &amp; race == 1)]) - mean(Y[which(W == 0 &amp; gender == 1 &amp; race == 1)]) w1 &lt;- sum(gender == 1 &amp; race == 1) / N # female-Whites tau_hat2 &lt;- mean(Y[which(W == 1 &amp; gender == 1 &amp; race == 0)]) - mean(Y[which(W == 0 &amp; gender == 1 &amp; race == 0)]) w2 &lt;- sum(gender == 1 &amp; race == 0) / N # male-Blacks tau_hat3 &lt;- mean(Y[which(W == 1 &amp; gender == 0 &amp; race == 1)]) - mean(Y[which(W == 0 &amp; gender == 0 &amp; race == 1)]) w3 &lt;- sum(gender == 0 &amp; race == 1) / N # male-Whites tau_hat4 &lt;- mean(Y[which(W == 1 &amp; gender == 0 &amp; race == 0)]) - mean(Y[which(W == 0 &amp; gender == 0 &amp; race == 0)]) w4 &lt;- sum(gender == 0 &amp; race == 0) / N tau_hat &lt;- tau_hat1 * w1 + tau_hat2 * w2 + tau_hat3 * w3 + tau_hat4 * w4 tau_hat2 &lt;- mean(Y[W == 1]) - mean(Y[W == 0]) # a mis-specified regression model reg &lt;- lm(Y ~ W + gender) reg_tau &lt;- coefficients(reg)[[2]] return(list(table(gender[W == 1]), table(race[W == 1]), tau_hat, tau_hat2, reg_tau)) } ATE2_results &lt;- fun_ATE2(N = 20000, tau = 10) print(paste(c(&quot;treated males: &quot;, &quot;treated females: &quot;) , ATE2_results[[1]])) ## [1] &quot;treated males: 2930&quot; &quot;treated females: 7132&quot; print(paste(c(&quot;treated Whites: &quot;, &quot;treated Blacks: &quot;) , ATE2_results[[2]])) ## [1] &quot;treated Whites: 4023&quot; &quot;treated Blacks: 6039&quot; print(paste(&quot;ATE conditioned on Xs is :&quot;, ATE2_results[[3]])) ## [1] &quot;ATE conditioned on Xs is : 10.2117589356295&quot; print(paste(&quot;ATE not conditioned on Xs is :&quot;, ATE2_results[[4]])) ## [1] &quot;ATE not conditioned on Xs is : 19.429031336071&quot; # get tau_hats from replications store &lt;- rep(0, reps) store2 &lt;- store store.reg &lt;- store for(i in 1:reps){ ATE.results &lt;- fun_ATE2(N = 20000, tau = 10) store[i] &lt;- ATE.results[[3]] store2[i] &lt;- ATE.results[[4]] store.reg[i] &lt;- ATE.results[[5]] } # histogram of tau_hat conditioned hist(store, main = &quot;tau hats conditioned&quot;) print(paste(&quot;The standard error from the conditioned approach is:&quot;, sd(store))) ## [1] &quot;The standard error from the conditioned approach is: 0.0806789426271598&quot; hist(store2, main = &quot;tau hats not conditioned&quot;) The ATT estimate is much closer to the true parameter, 10, when conditioned upon the covariates as compared to an unconditional approach (where the distribution of ATT estimate is centered around 19.3). This example highlights the importance of conditioning on \\(X\\)s when evaluating the treatment effects if the treatment assignment is correlated with the potential outcomes. In this case, Blacks and females are more likely to have higher scores in general even without the treatment and both of these subgroups are also more likely to be treated. Treatment is not only non-random but is systematically correlated with the outcomes. Since we have the perfect information on the treatment assignment mechanism, after conditioning for the covariates the treatment assignment is essentially random. In other words, within Black vs. White race groups, for example, the treatment assignment is randomly allocated. This allows estimation of ATE for each subgroup or strata. After estimating ATE for each strata, the ATEs are averaged using the sample size of the strata as weights. One problem with the approach highlighted above is that in complex settings, with many determinants (multi-dimensionality) of treatment or in presence of continuous covariates, the sub-space required for the analyses highlighted above will be thinned out too soon. As an alternative, regression framework has been rigorously used as a tool-kit to control for covariates. While there are benefits of using a regression framework, it is by nomeans a panacea. This is especially true if the regression models are misspecified. Below we will use a misspecified version of the regression model to see if we can recover the treatment estimate close to the true value. print(paste(&quot;ATE estimated from misspecified regression model:&quot;, ATE2_results[[5]])) ## [1] &quot;ATE estimated from misspecified regression model: 14.2099725133731&quot; print(paste(&quot;The standard error is:&quot;, sd(store.reg))) ## [1] &quot;The standard error is: 0.179190788352466&quot; hist(store.reg, main = &quot;Treatment effects using regression&quot;) The terms unconfoundedness and conditional independence (\\(heart\\; disease \\perp age \\; | \\; cholestrol\\)) are used interchangebly in causal inference literature. Conditional independence is a broader term that relates to the general field of probability and statistics, whereas unconfoundedness is more specific to causal inference. Unconfoundedness implies a specific kind of conditional independence, specific to causal inference.↩︎ "],["discussion.html", "2.7 Discussion", " 2.7 Discussion In our discussion, we explored the causal effect through the lens of the potential outcome framework, emphasizing the crucial assumptions needed for its accurate identification. We particularly focused on the independence assumption and the unconfoundedness assumption, alongside the Stable Unit Treatment Value Assumption (SUTVA) and the overlap assumption. These assumptions play a pivotal role in ensuring valid causal inference, with the conditional independence assumption being highly effective in randomized controlled trials. However, in observational studies where randomization is not possible, the conditional independence assumption can be quite stringent and challenging to meet as there might be unobserved variables driving the treatment assignment. Consequently, it is essential to leverage alternative methodologies designed for observational settings. Exploring approaches such as propensity score matching, instrumental variables, regression discontinuity design, and difference-in-differences can help overcome these challenges and improve the robustness of causal effect estimation when randomization is not feasible. By employing these methods, we can better navigate the complexities of observational data and draw more reliable causal inferences. "],["reference.html", "2.8 Reference", " 2.8 Reference "],["ipw-and-aipw.html", "3 IPW and AIPW", " 3 IPW and AIPW The target is to estimate the average treatment effect (ATE): \\[\\begin{equation} \\label{eq:ATE} ATE = E[Y_i(1) - Y_i(0)] \\tag{3.1} \\end{equation}\\] Note that using the following two assumptions: \\(W_i \\perp \\{Y_i(0), \\; Y_i(1)\\}\\) (independence assumption) \\(Y_i(W) = Y_i\\) (SUTVA) the ATE estimate \\(\\hat{\\tau}\\) can be written as the difference-in-means estimator: \\[\\begin{equation} \\label{eq:ATE_estimator} \\hat{\\tau} = \\frac{1}{N_T} \\sum_{W_i = 1} Y_i - \\frac{1}{N_C} \\sum_{i \\in W_i = 0} Y_i \\end{equation}\\] where \\(N_T\\) and \\(N_C\\) are the number of treated and control units, respectively. In the previous lecture, we disscussed randomized control trial as an ideal approach to estimate ATE. In a randomized controlled trial each unit has an equal probability of receiving the treatment. This means the following: \\[\\begin{equation} P(W_i = 1 \\; | \\; Y_i(0), \\; Y_i(1), \\; n_T) = \\frac{n_T}{n}, \\; \\; i = \\{1, ...., n\\} \\tag{3.2} \\end{equation}\\] In equation (3.2), \\(n_T\\) refers to the number of units that receives the treatment.3 In an easy to understand set-up, if a researcher wants \\(P(W_i = 1) = 0.5\\) (unit is equally likely to be treated or untreated), a coin flip can feasibly be used as a mechanism to assign treatment.4 Although randomized controlled trials (RCTs) are often considered the gold standard in causal inference, they cannot always be used due to ethical, moral, and monetary reasons. Returning to the example we used in the previous chapter, it is not ethical to demarcate who can attend the tutoring session versus who cannot. In real-world scenarios, tutoring sessions are typically voluntary. Students who regularly attend these sessions may have different baseline (pre-treatment) characteristics compared to those who do not attend. These differences can introduce biases that complicate causal inference in observational studies. To proceed further in observational setting (without using RCTs), we require more knowledge about the treatment assignment. In other words, we need to understand which variables determine who attends the tutoring sessions. This information is crucial for identifying potential confounders and for applying methods that can help estimate causal effects in observational settings. In causal inference, confounders are variables that are associated with both the treatment and the outcome. They can introduce bias in the estimation of the causal effect of the treatment on the outcome by providing alternative explanations for any observed relationships. For example, say you are trying to evaluate the efficacy of a new drug on blood pressure level. If smokers are more likey to get treated and if they tend to have higher blood pressure to begin with, the treatment effects are likely to be understated. This brings us to the unconfoundedness assumption. Unconfoundedness: The treatment assignment is as good as random once we control for \\(X\\)s. \\[\\begin{equation} \\{W_i \\perp \\{Y_i(0), \\; Y_i(1)\\} | X_i \\} \\; for \\; all \\; x \\in \\chi. \\tag{3.3} \\end{equation}\\] As with the tutoring example, the independence assumption (discussed in the previous chapter) is highly unlikely to hold in observational settings. Let’s consider the following scenarios: Out of the ten states that are yet to expand Medicaid, eight fall in South. Medicaid expansion is not random. Cigarette taxes are higher in states with higher anti-smoking sentiments. Infrastructure development, such as construction of roads, schools, hopitals, are demand-driven. The list goes on .. However, if we manage to observe all the \\(X\\)s (covariates) that influence the treatment, we can invoke unconfoundedness for causal inference. Although it is generally recommended to assign half of the sample to the treatment group and the other half to the control group, this is not a strict requirement.↩︎ Of course, this is quicky going to be inefficient as the sample size increases. In general, treatment assignment is determinted by a statistical process via a software. For example, if a researcher wants about one-third of the sample treated then a bernoulli trial with the probability of success of 0.33 can be used.↩︎ "],["a-simple-example.html", "3.1 A simple example", " 3.1 A simple example Say, you are interested in evaluating the effect of tutoring program initiated following the first exam on grades at an introductory level course. For simplicity, the possible grades are A and B. However, students who received B on their first exam are more likely to attend the tutoring session. In other words, \\(P(W_i = 1 | Y_{iFE} = A) &lt; P(W_i = 1 | Y_{iFE} = B)\\) (\\(Y_{iFE}\\) is read as unit \\(i&#39;s\\) grade in the first exam). In this case, the treatment assignment is correlated with the past grade, which can predict the grade on the second exam. In other words, if you did well in the first exam, you are likely to perform well in the second exam and so on. Hence, using equation (2) to estimate effects of the tutoring program will result in biased estimate. Since we know that the probability of treatment is influenced by the grade on the first exam, we can estimate the conditional average treatment effect (CATE) and average them using weights to form an estimate of ATE. Let’s take a look at the data. # function to report grade breakdown by the first exam grade (A and B) grade_mat &lt;- function(grade_vec){ grade &lt;- matrix(0, nrow =2, ncol = 3) grade[, 1] &lt;- c(&quot;Treat&quot;, &quot;Control&quot;) grade[ ,2] &lt;- c(grade_vec[1], grade_vec[2]) grade[ ,3] &lt;- c(grade_vec[3], grade_vec[4]) return(grade) } # Y_iFS == A grade &lt;- grade_mat(c(5, 9, 2, 4)) colnames(grade) &lt;- c(&quot; &quot;, &quot;A (2nd Exam)&quot;, &quot;B (2nd Exam)&quot;) # Se grade %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot;Table 1.&quot; = 1, &quot;Grade in the 2nd exam | 1st exam = A&quot; = 2)) Table 1. Grade in the 2nd exam | 1st exam = A A (2nd Exam) B (2nd Exam) Treat 5 2 Control 9 4 grade &lt;- grade_mat(c(15, 1, 5, 4)) colnames(grade) &lt;- c(&quot; &quot;, &quot;A (2nd Exam)&quot;, &quot;B (2nd Exam)&quot;) grade %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot;Table 2.&quot; = 1, &quot;Grade in the 2nd exam | 1st exam = B&quot; = 2)) Table 2. Grade in the 2nd exam | 1st exam = B A (2nd Exam) B (2nd Exam) Treat 15 5 Control 1 4 \\(~\\) \\(~\\) Estimation \\(\\hat{\\tau}_{FE=A} = \\frac{5}{7} - \\frac{9}{13} = 2.1 \\; pp\\) \\(\\hat{\\tau}_{FE=B} = \\frac{15}{20} - \\frac{1}{5} = 55 \\; pp\\) \\(\\hat{\\tau}_{AGG} = \\frac{20}{45} \\hat{\\tau}_{FE=A} - \\frac{25}{45} \\hat{\\tau}_{FE=B} = 31.48 \\; pp\\). The first two are CATEs for the group that recived A and B in the first exam. The assumption is that once conditioned on the grade in the first exam, treatment (who attends vs. who doesn’t) is random. This allows valid estimation of within group causal effects, which are then averaged to form ATE using appropriate weights on the third line. This simple example using the discrete feature space (grade in the first exam can be A or B) provides intuition that if variables influencing the treatment assignment are observed then ATE estimate can be uncovered by taking weighted average of CATE estimates (these are also group-wise ATE).5 In this case, CATEs are different across the two sub-groups. Sometimes the core interest of analysis can be uncovering the heterogeneous treatment effects, which motivates estimation and inference on CATEs across two or more sub-groups.↩︎ "],["aggregated-estimator.html", "3.2 Aggregated Estimator", " 3.2 Aggregated Estimator As we saw in Section 1, aggregated estimator can be used in when we know what exact variables are determining the treatment assignment. We will consider the discrete case, when a discrete covariate determines the probability of treatment for simplicity. Note that students who received B on their first exam are more likely to attend the tutoring session in our simple example. So grade in the first exam (A or B for simplicity) determines the treatment here. Setup. \\(Y_i\\) is the outcome variable; final exam score. \\(W_i\\) is the treatment variable; whether a student attended the tutoring session. \\(X_i\\) is the covariate; a student’s grade on the first exam. We want to evaluate the effects of attending a tutoring program on a student’s exam score. What we would want to do is to condition on the first exam’s grade, estimate the treatment effects, and aggregate it. The aggregated estimator is given as: \\[\\begin{align} \\hat{\\tau}_{AGG} = \\frac{n_{A}}{n} \\bigg[\\frac{1}{n_{A1}} \\underbrace{\\sum}_{\\substack{i \\in A \\\\ \\textrm{W = 1}}} Y_i - \\frac{1}{n_{A0}} \\underbrace{\\sum}_{\\substack{i \\in A \\\\ \\textrm{W = 0}}} Y_i \\bigg] + \\frac{n_{B}}{n} \\bigg[\\frac{1}{n_{B1}} \\underbrace{\\sum}_{\\substack{i \\in B \\\\ \\textrm{W = 1}}} Y_i - \\frac{1}{n_{B0}} \\underbrace{\\sum}_{\\substack{i \\in B \\\\ \\textrm{W = 0}}} Y_i \\bigg] \\tag{3.4} \\end{align}\\] Note that the first block is the treatment effect for those who received A on their first exam, whereas the second block represents treatment effect for those who received B. After a few steps of simple algebra, equation @ref{eq:AGG0} can be written as: \\[\\begin{equation} = \\frac{1}{n} \\bigg[ \\frac{1}{\\frac{n_{A1}}{n_{A}}} \\underbrace{\\sum}_{\\substack{i \\in A}} Y_i \\times W_i - \\frac{1}{\\frac{n_{A0}}{n_{A}}} \\underbrace{\\sum}_{\\substack{i \\in A}} Y_i \\times (1 - W_i) \\bigg] + \\\\ \\frac{1}{n} \\bigg[ \\frac{1}{\\frac{n_{B1}}{n_{B}}} \\underbrace{\\sum}_{\\substack{i \\in B}} Y_i \\times W_i - \\frac{1}{\\frac{n_{B0}}{n_{B}}} \\underbrace{\\sum}_{\\substack{i \\in B}} Y_i \\times (1 - W_i) \\bigg] \\tag{3.5} \\end{equation}\\] Equation (3.5) looks super complicated, buts its not. Let’s breakdown the components of it: \\(\\frac{n_{A1}}{n_A}:\\) Represents the fraction of treated individuals who received \\(A\\) on the first exam. \\(\\frac{n_{A0}}{n_A}:\\) Represents the fraction of untreated individuals who received \\(A\\) on the first exam. \\(\\frac{n_{B1}}{n_B}:\\) Represents the fraction of treated individuals who received \\(B\\) on the first exam. \\(\\frac{n_{B0}}{n_B}:\\) Represents the fraction of untreated individuals who received \\(B\\) on the first exam. Note that \\(\\frac{n_{A1}}{n_A} = e(X = A)\\) and \\(\\frac{n_{A0}}{n_A} = 1 - e(X = A)\\) and the same goes with the segment composed of those who received B on their first exam. Equation (3.5) can be further simplified as: \\[\\begin{equation} \\hat{\\tau}_{AGG} = \\frac{1}{n}\\bigg[ \\sum \\frac{Y_i \\times W_i}{e(X)} - \\sum \\frac{Y_i \\times (1-W_i)}{1 - e(X)} \\bigg] \\tag{3.6} \\end{equation}\\] Equation @ref{eq:AGG2} takes the form of an inverse probability-weighted estimator. We’ll find out that Aggregate Estimator \\((\\hat{\\tau}_{AGG})\\) is a special case of Inverse Probability Weighting later on in this section. n &lt;- 2000 p &lt;- 10 true_effect &lt;- 10 set.seed &lt;- 12570 agg.means &lt;- replicate(1000, { X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) prob &lt;- 1 / (1 + exp(- (X[, 1] &lt; 1 + rnorm(n)))) W &lt;- rbinom(n, 1, prob) Y &lt;- 60 + true_effect * W + 5 * pmax(X[, 1], 1) + rnorm(n) group &lt;- ifelse( X[, 1] &lt; 1, &quot;A&quot;, &quot;B&quot; ) # estimates for those receiving A and B on the first exam att.A &lt;- mean(Y[group == &quot;A&quot; &amp; W == 1]) - mean(Y[group == &quot;A&quot; &amp; W == 0]) att.B &lt;- mean(Y[group == &quot;B&quot; &amp; W == 1]) - mean(Y[group == &quot;B&quot; &amp; W == 0]) prop.A &lt;- mean(group == &quot;A&quot;) prop.B &lt;- mean(group == &quot;B&quot;) prop.A * att.A + prop.B * att.B } ) # plot(X[, 1], X[, 2], col = as.factor(W)) hist(agg.means, freq = F, main = &quot;&quot;, col= rgb(0, 0, 1, 1/8), xlab = &quot;ATT estimates&quot;, las = 1) abline(v = true_effect, lwd = 3, lty = 2) legend(&quot;topright&quot;, &quot;True effect&quot;, lwd = 3, lty = 2, bty = &quot;n&quot;) paste(&quot;mean of AGG estimates: &quot;, round(mean(agg.means), 3)) ## [1] &quot;mean of AGG estimates: 9.959&quot; paste(&quot;standard error of AGG estimates: &quot;, round(sd(agg.means), 3)) ## [1] &quot;standard error of AGG estimates: 0.062&quot; Let’s compare this to a naive estimator. set.seed &lt;- 12570 naive.means &lt;- replicate(1000, { X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) prob &lt;- 1 / (1 + exp(- (X[, 1] &lt; 1 + rnorm(n)))) W &lt;- rbinom(n, 1, prob) Y &lt;- 60 + true_effect * W + 5 * pmax(X[, 1], 1) + rnorm(n) # naive estimates that does not take voluntary selection into account mean(Y[ W == 1]) - mean(Y[ W == 0]) } ) # plot(X[, 1], X[, 2], col = as.factor(W)) hist(naive.means, freq = F, main = &quot;&quot;, col= rgb(0, 0, 1, 1/8), xlab = &quot;ATT naive estimates&quot;, las = 1) abline(v = true_effect, lwd = 3, lty = 2) legend(&quot;topright&quot;, &quot;True effect&quot;, lwd = 3, lty = 2, bty = &quot;n&quot;) paste(&quot;mean of naive estimates: &quot;, round(mean(naive.means), 3)) ## [1] &quot;mean of naive estimates: 9.764&quot; paste(&quot;standard error of naive estimates: &quot;, round(sd(naive.means), 3)) ## [1] &quot;standard error of naive estimates: 0.082&quot; "],["propensity-score.html", "3.3 Propensity score", " 3.3 Propensity score Previously we discussed the setting of a discrete feature in which case we estimate group-wise ATEs and use the weighted average to obtain an overall ATE estimate. When there are many features (covariates), this approach is prone to the curse of dimensionality.6 Moreover, if features are continuous, we won’t be able to estimate ATE at each value of \\(x \\in \\chi\\) due to lack of enough sample size. Instead of estimating group-wise ATE and averaging them, we would want to use a more indirect approach. This is when propensity score comes in. The implicit assumption is that we have collected enough features (discrete, continuous, interaction terms, higher degree polynomials) to back unconfoundedness. This again means that the treatment assignment is as good as random after controlling for \\(X_i\\). More formally, this us back to equation (3.3). But in actuality we are not interested in splitting groups to estimate group-wise treatment effects in the case when covariates are continuous and there are many characteristics determining the treatment assignment. Propensity score: \\(e(x)\\). The probability of being treated given a set of covariates \\(X\\)s. \\[\\begin{equation} e(x) = P(W_i = 1 | X_i = x) \\tag{3.7} \\end{equation}\\] The key property of the propensity score is that it balances units in the treatment and control groups. If unconfoundedness assumption holds, we can write the following: \\[\\begin{equation} W_i \\perp \\{Y_i(0), \\; Y_i(1)\\} | \\; e(X_i) \\tag{3.8} \\end{equation}\\] What equation (3.8) says is that instead of controlling for \\(X\\) one can control for the probability of treatment \\((e(X))\\) to establish the desired property that the treatment is as good as random. The propensity scores are mainly used for balancing purposes. One straight-forward implication of equation (3.8) is that if we partition observations into groups with similar propensity score then we can estimate group-wise treatment effects and aggregate them to form an estimate for ATE. This can be done using the propensity score stratification method. The argument here is that when units with similar propensity scores are compared, the covariates are approximately balanced, mimicking a randomized experiment. As the number of covariates increases the domain space shrinks quite rapidly making it infeasible to estimate ATE within the given domain due to thinning out data.↩︎ "],["estimation-of-propensity-score.html", "3.4 Estimation of propensity score", " 3.4 Estimation of propensity score Propensity scores can be estimated using various statistical or machine learning models. We will first estimate propensity score using a logistic regression model, where the treatment assignment \\(W\\) is regressed on the covariates \\(X\\). Next, we will estimate propensity score using random forest model built within the GRF framework in Athey et al.  Logistic Regression Using a linear regression framework to predict probabilities when the outcome is binary \\(\\{0, \\; 1\\}\\) falls short since the predicted values can go beyond 0 and 1. Many models contain values within the range of 0 and 1, which can be used to model a binary response. The logistic regression uses a logistic function given as: \\[\\begin{equation} p(X) = \\frac{e^{\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + .... \\beta_p X_p}}{1 + e^{\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + .... \\beta_p X_p}} \\tag{3.9} \\end{equation}\\] It is easy to see that \\(lim_{a \\rightarrow - \\inf}[\\frac{e^a}{1+e^a}] = 0\\) and \\(lim_{a \\rightarrow \\inf}[\\frac{e^a}{1+e^a}] = 1\\). Equation @ref{eq:logit} can be transformed using the logit transformation given as: \\[\\begin{equation} g(X) = ln[\\frac{p(X)}{1-p(X)}] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + .... \\beta_p X_p \\end{equation}\\] We want to fit a logistic regression in order to predict the probability. For now, we will use simulated data. # helper packages library(dplyr) # data wrangling library(ggplot2) # plots library(rsample) # data splitting library(tidyr) # for reshaping, pivot_wider ## ## Attaching package: &#39;tidyr&#39; ## The following objects are masked from &#39;package:Matrix&#39;: ## ## expand, pack, unpack # Modeling package library(caret) # for logistic regression modeling # Model interpretability library(vip) ## ## Attaching package: &#39;vip&#39; ## The following object is masked from &#39;package:utils&#39;: ## ## vi set.seed(194) # for replicability # Generate simulated Data n &lt;- 2000 # number of obsevations p &lt;- 10 # number of covariates X &lt;- matrix(rnorm(n * p), n, p) # data matrix true_effect &lt;- 2.5 W &lt;- rbinom(n, 1, 0.1 + 0.4 * (X[, 1] &gt; 0) + 0.2 * (X[, 2] &gt; 0)) prob &lt;- 0.1 + 0.4 * (X[, 1] &gt; 0) + 0.2 * (X[, 2] &gt; 0) # oracle propensity score Y &lt;- true_effect * W + X[, 2] + pmax(X[, 1], 0) + rnorm(n) #plot(X[, 1], X[, 2], col = as.factor(W)) dat &lt;- data.frame(cbind(W, Y, X)) colnames(dat) &lt;- c(&quot;W&quot;, &quot;Y&quot;, paste0(&quot;X&quot;, seq(1, 10))) dat &lt;- dat %&gt;% mutate(W = as.factor(W)) # create 70% training and 30% test data churn_split &lt;- initial_split(dat, prop = 0.7) dat_train &lt;- training(churn_split) dat_test &lt;- testing(churn_split) # dimension of training and testing data print(dim(dat_train)) ## [1] 1400 12 print(dim(dat_test)) ## [1] 600 12 # let&#39;s compare two different models # using X1 as the predictor cv_model1 &lt;- train( W ~ X1 + X2 + X3 + X4, data = dat_train, method = &quot;glm&quot;, family = &quot;binomial&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10) ) # misses out on X1 cv_model2 &lt;- train( W ~ X2 + X3 + X4, data = dat_train, method = &quot;glm&quot;, family = &quot;binomial&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10) ) # print the sample performance measures sum_performance &lt;- summary( resamples( list( model1 &lt;- cv_model1, model2 &lt;- cv_model2 ) ) ) sum_performance$statistics$Accuracy ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## Model1 0.6043165 0.6446429 0.6678571 0.6706292 0.6964286 0.7285714 0 ## Model2 0.5642857 0.5785714 0.5892392 0.5935621 0.6160714 0.6285714 0 # use the confusion matrix # predict class threshold &lt;- 0.5 pred_prob &lt;- predict(cv_model1, dat_train, type = &quot;prob&quot;) pred_class_manual &lt;- rep(0, 1400) pred_class_manual[pred_prob[, 2] &gt;= 0.5] &lt;- 1 pred_class &lt;- predict(cv_model1, dat_train) # print the confusion matrix confusionMatrix( data = relevel(pred_class, ref = &quot;1&quot;), # predictions reference = relevel(dat_train$W, ref = &quot;1&quot;) # reference or the true value ) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 1 0 ## 1 270 151 ## 0 299 680 ## ## Accuracy : 0.6786 ## 95% CI : (0.6534, 0.703) ## No Information Rate : 0.5936 ## P-Value [Acc &gt; NIR] : 3.164e-11 ## ## Kappa : 0.3053 ## ## Mcnemar&#39;s Test P-Value : 4.219e-12 ## ## Sensitivity : 0.4745 ## Specificity : 0.8183 ## Pos Pred Value : 0.6413 ## Neg Pred Value : 0.6946 ## Prevalence : 0.4064 ## Detection Rate : 0.1929 ## Detection Prevalence : 0.3007 ## Balanced Accuracy : 0.6464 ## ## &#39;Positive&#39; Class : 1 ## # if predict all yes still get an accuracy of 0.5936 table(dat_train$W) %&gt;% prop.table() ## ## 0 1 ## 0.5935714 0.4064286 Looking at the confusion matrix, the values on the downward diagonal ([1, 1] and [2, 2] in matrix) are correctly idenfified by the model, while the upward diagonal values ([2, 1] and [1, 2]) are incorrectly classified. If all of the observations were assigned the value of 0, the accuracy would still be 0.5936%. This is termed as the no information rate. The model performs quite well in predicting True Negatives (classify as 0, when the value is actually 0). However, it does not perform so well in classifying the True Positives – more than 50% of the positive cases are classified as negative. Next, two measures of importance are sensitivity and specificity. The sensitivity measure tracks the true positive rate from the model, while the specificity measure tracks the true negative rate. \\(sensitivity = \\frac{True \\; positives}{True \\; positives + False \\; negatives} = 0.8790\\). \\(specificity = \\frac{True \\; negatives}{True \\; negatives \\; + \\; False \\; positives} = \\frac{604}{604 + 85} = 0.8766\\). How are the observations classified? A threshold value is used to transform the raw prediction of probabilities into classification such that \\(P(Y_{i} &gt; p_{threshold})=1.\\) The implicit \\(p_{threshold}\\) used is 0.5. Varying the threshold from 0 to 1, one can calculate the relationship between the False Positive Rate (the prediction is positive when in actual the outcome is negative) and True Positive Rate at each threshold value. If the threshold value \\((p_{threshold})\\) is 1, then all observations are classified as 0, which means that the False Positive Rate is 0 but so is the True Positive Rate. Similarly, if the threshold is 0, then both True and False positive rates are 1. This gives the Receiver Operating Characteristic (ROC). library(ROCR) # compute probabilities m1_prob &lt;- predict(cv_model1, dat_train, type = &quot;prob&quot;)[, 2] m2_prob &lt;- predict(cv_model2, dat_train, type = &quot;prob&quot;)[, 2] # AUC metrics perf1 &lt;- prediction(m1_prob, dat_train$W) %&gt;% performance(measure = &quot;tpr&quot;, x.measure = &quot;fpr&quot;) perf2 &lt;- prediction(m2_prob, dat_train$W) %&gt;% performance(measure = &quot;tpr&quot;, x.measure = &quot;fpr&quot;) # plot ROC curves plot(perf1, col = &quot;red&quot;) plot(perf2, add = TRUE, col = &quot;green&quot;) legend(0.8, 0.2, legend = c(&quot;cv_model1&quot;, &quot;cv_model2&quot;), lty = c(1,1), col = c(&quot;red&quot;, &quot;green&quot;), cex = 0.6) Figure 3.1: ROC The figure above plots the ROC for two models that we tested using cross-validation. The cv_model2 produces a diagonal line, which means that this model is as good as a random guess. Next, cv_model1 performs a whole lot better since a large gains in True positive rate can be achieved with a relatively small increase in False positive rate at the start. The ROC curve pertaining to cv_model1 helps pick a threshold to balance the sensitivity (True Positive Rate) and specificity (1 - False Positive Rate). The histogram of the estimated propensity scores using the logistic regression is as: hist(pred_prob[, 2], main = &quot;Histogram of P(W=1|X) \\n using Logistic Regression&quot;, xlab = &quot;probabilities&quot;) Now, let’s take a look at the confusion matrix using the test data. pred_class_test &lt;- predict(cv_model1, dat_test) # print the confusion matrix this time for the test sample confusionMatrix( data = relevel(pred_class_test, ref = &quot;1&quot;), # classification from the prediction reference = relevel(dat_test$W, ref = &quot;1&quot;) # ground truth ) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 1 0 ## 1 94 69 ## 0 131 306 ## ## Accuracy : 0.6667 ## 95% CI : (0.6274, 0.7043) ## No Information Rate : 0.625 ## P-Value [Acc &gt; NIR] : 0.01882 ## ## Kappa : 0.2474 ## ## Mcnemar&#39;s Test P-Value : 1.608e-05 ## ## Sensitivity : 0.4178 ## Specificity : 0.8160 ## Pos Pred Value : 0.5767 ## Neg Pred Value : 0.7002 ## Prevalence : 0.3750 ## Detection Rate : 0.1567 ## Detection Prevalence : 0.2717 ## Balanced Accuracy : 0.6169 ## ## &#39;Positive&#39; Class : 1 ## The measures of accuracy, sensitivity, and specificity are similar for both the training and testing sample. "],["using-cross-fitting-to-predict-propensity-score.html", "3.5 Using cross-fitting to predict propensity score", " 3.5 Using cross-fitting to predict propensity score Here, we will be using 10-fold cross-folding to predict propensity score. fun_probit_predict &lt;- function(predictfold){ # @Arg predictfold: number of the fold to avoid for model traning # but used for prediction cv_model1 &lt;- train( W ~ X1 + X2 + X3 + X4, data = dat[-predictfold, ], method = &quot;glm&quot;, family = &quot;binomial&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10) ) predict_logit &lt;- predict(cv_model1, dat[predictfold, ], type = &quot;prob&quot;) return(predict_logit[, 2]) } ############################## # # cross-fitting # ############################## k &lt;- 10 # number of folds len &lt;- nrow(dat) ind &lt;- sample(1:len, replace = FALSE, size = len) fold &lt;- cut(1:len, breaks = k, labels = FALSE) # create 10 folds fold &lt;- fold[ind] # randomly allocate the folds by ind # container to store the predicted values store &lt;- c() true_index &lt;- c() # do the cross-fitting and store for(i in 1:k){ # which(fold == i) is used as an index, if 8th observation receives the 1st fold for the first time, # then the 1st prediction value corresponds to the 8th obs store_new &lt;- fun_probit_predict(predictfold = which(fold == i)) store_new &lt;- as.numeric(as.character(store_new)) true_index_new &lt;- which(fold == i) store &lt;- c(store, store_new) true_index &lt;- c(true_index, true_index_new) } # create a dataframe with index that maps the predictions with the actual data store &lt;- data.frame(pscore = store, index = true_index) # sort by index store &lt;- store[order(store[, 2]), ] # propensity score dat &lt;- dat %&gt;% mutate(pscore = store$pscore) # histogram of propensity score hist(dat$pscore, main = &quot;propensity score \\n from cross-fitting&quot;) "],["propensity-score-stratification.html", "3.6 Propensity score stratification", " 3.6 Propensity score stratification Propensity scores are super important as they can be used in various different approaches to enchance the validity of causal inference in observational settings. These include but are not limited to inverse probability weighting, matching estimates, weight adjustments in regression (for better balancing), trimming, and propensity score stratification. These methods will be discussed in detail as we move on with the course. First, let’s take a look at propensity score stratification to get a gist of how propensity scores contribute in comparing treatment units with control units. The simple idea is given by the cliché that we want to compare oranges with oranges and not apples. To bring focus back into our context, it simply means that it is no good comparing a treated unit with an extremely high probability of receiving the treatment with a control unit with super low probability of receiving the treatment. But what if (yes, what if) we compare units with similar treatment probabilities? Let’s run a quick thought experiment. We run the logistic regression and estimate the propensity score. Say, we have two units, each from the treatment and control group, with the propensity score of 0.6. The assumption here is, conditional on the similar propensity score, the treatment assignment is random. This follows from the unconfoundedness assumption: \\(Y_i^{0}, \\; Y_i^{1} \\; \\perp \\; W_i \\; | X_i\\). Propensity score stratification divides the estimates of propensity scores into several segments and estimates the ATE within each segment. Finally, these segment-specific ATE estimates are averaged to obtain the overall estimate of ATE. Steps for ATE estimation using propensity score stratification Order observations according to their estimated propensity score. \\(\\hat{e}(X)_{i1}, \\; \\hat{e}(X)_{i2}, ... \\; \\hat{e}(X)_{iN}\\) Form \\(J\\) strata of equal size and take the simple difference in mean between the treated and control units within each strata. These are \\(\\hat{\\tau}_j\\) for \\(j = \\{1, \\; 2, \\; ..., \\; N\\}\\). Form the ATE, \\(\\hat{\\tau}_{Strat} = \\frac{1}{J} \\sum_{j = 1}^{J} \\hat{\\tau}_j\\) Here, \\(\\hat{\\tau}_{Strat}\\) is consistent for \\(\\tau\\), meaning that \\(\\hat{\\tau}_{Strat} \\rightarrow_p \\tau\\) given that \\(\\hat{e}(x)\\) is consistent for \\(e(x)\\) and the number of strata grows appropriately with \\(N\\). However, one needs to set the number of strata, which can be a bit ad-hoc. Demo of propensity score stratification # order data by the propensity score: low to high dat &lt;- dat[order(dat$pscore), ] # cut to form ventiles strata &lt;- cut(dat$pscore, breaks = quantile(dat$pscore, seq(0, 1, 0.05)), labels = 1:20, include.lowest = TRUE) dat &lt;- dat %&gt;% mutate(strata = strata) # compare across strata dat_sum &lt;- dat %&gt;% group_by(W, strata) %&gt;% summarize(mean_Y = mean(Y)) %&gt;% pivot_wider(names_from = W, values_from = mean_Y) ## `summarise()` has grouped output by &#39;W&#39;. You can override using the `.groups` argument. colnames(dat_sum) &lt;- c(&quot;strata&quot;, &quot;mean_control&quot;, &quot;mean_treat&quot;) dat_sum &lt;- dat_sum %&gt;% mutate(diff = mean_treat - mean_control) print(paste(&quot;ATE Estimation from propensity score stratification is: &quot;, mean(dat_sum$diff), sep = &quot;&quot;)) ## [1] &quot;ATE Estimation from propensity score stratification is: 2.50135397640408&quot; print(paste(&quot;raw difference is :&quot;, mean(dat$Y[dat$W == 1]) - mean(dat$Y[dat$W == 0]), sep = &quot;&quot;)) ## [1] &quot;raw difference is :3.04098842187519&quot; print(paste(&quot;And the true treatment effect is :&quot;, true_effect, sep = &quot;&quot;)) ## [1] &quot;And the true treatment effect is :2.5&quot; We see that the estimate from stratification gets closer to the true effect compared to the mean difference estimator. Looks like given that we know and observe what variables determine the treatment assignment, propensity score stratification approach performs well in estimating the ATE. "],["inverse-probability-weighting-ipw.html", "3.7 Inverse Probability Weighting (IPW)", " 3.7 Inverse Probability Weighting (IPW) A more natural way to exploit the condition of unconfoundedness is to weight observations by their propensity score, which is known as the inverse probability weighting. As before \\(\\hat{e}(x)\\) is defined as an estimated propensity score. \\[\\begin{equation} \\hat{\\tau}_{IPW} = \\frac{1}{N}\\sum_{i = 1}^{N} \\Bigg(\\frac{Y_i . W_i}{\\hat{e}(X_i)} - \\frac{Y_i . (1-W_i)}{1 - \\hat{e}(X_i)}\\Bigg) \\tag{3.10} \\end{equation}\\] Intuitively, observations with high propensity score within the treated group are weighted down, while observations with higher propensity score in the control group are weighted more. In this way, propensity score is used to balance the differences in covariates across the treatment and control groups. Note that the validity of \\(\\hat{\\tau}\\) still hinges on the unconfoundedness assumption. Any inference that you make is only good if your assumption holds. Limitation of IPW Estimate. One way to analyze the accuracy of \\(\\hat{\\tau}_{IPW}\\) is to compare it with the oracle IPW estimate, \\(\\hat{\\tau}_{IPW}^{*}\\). The oracle estimate is obtained from the known propensity score. Briefly, comparison between \\(\\hat{\\tau}_{IPW}^{*}\\) and \\(\\hat{\\tau}_{AGG}\\) suggests that the oracle IPW under-performs \\(\\hat{\\tau}_{AGG}\\). In other words, the variance of the oracle estimate is larger than that of \\(\\hat{\\tau}_{AGG}\\). Algorithmically, we can form score as: \\((\\frac{Y_i \\times W_i}{\\hat{e}(X_i)} - \\frac{Y_i \\times (1-W_i)}{1 - \\hat{e}(X_i)})\\) The mean of it results to \\(\\hat{\\tau}\\) and the standard error of the estimate is simply \\(\\frac{\\hat{\\sigma}_{score}}{\\sqrt{N}}\\). Estimating IPW. In the example below we will simulate a dataset where the treatment assignment is made to be correlated with the outcome. This means that the independence assumption does not hold. However, since this is a simulated data, we know exactly what covariates influence the treatment assignment. Hence, we can invoke the unconfoundedness assumption. We estimate the propensity score using random forest based on honest splitting. For this, we use GRF package from . Note that \\(e(x)\\) is estimated via cross-fitting. The data is divided into \\(K\\)-folds. For each fold \\(k\\), model building is administered using \\(-k\\) folds. Using Step 2, predictions are generated for units in the \\(k^{th}\\) fold. Steps 2 and 3 are repeated until all \\(K\\) folds are exhausted. Estimation The following example uses 10 fold cross-fitting. ################################# # Author: VS # Last Revised: Jan 16, 2024 # Keywords: IPW, AIPW, GRF # # # ################################# set.seed(194) # Generate Data n &lt;- 2000 p &lt;- 10 true_effect &lt;- 15 X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) prob &lt;- 1 / (1 + exp(- (X[, 1] &gt; 1 + rnorm(n)))) W &lt;- rbinom(n, 1, prob) Y &lt;- 60 + true_effect * W + 5 * pmax(X[, 1], 0) + rnorm(n) plot(X[, 1], X[, 2], col = as.factor(W)) #paste0(&quot;average treatment effect is: &quot;, round(mean(pmax(X[, 1], 0)), 3)) ################################# ################################# # # Inverse Probability Weighting # ################################# ################################# # use the random forest to get the propensity score dat &lt;- data.frame(W, X, Y) n_features &lt;- length(setdiff(names(dat), &quot;W&quot;)) # A. ranger (probability tree) rf1_ranger &lt;- ranger( W ~ ., data = dat, mtry = min(ceiling(sqrt(n_features) + 20), n_features), num.trees = 2000, probability = TRUE ) # OOB predictions from ranger p.ranger &lt;- rf1_ranger$predictions[, 1] # B. probability tree using GRF # cross-fitting index K &lt;- 10 ind &lt;- sample(1:length(W), replace = FALSE, size = length(W)) folds &lt;- cut(1:length(W), breaks = K, labels = FALSE) index &lt;- matrix(0, nrow = length(ind) / K, ncol = K) for(f in 1:K){ index[, f] &lt;- ind[which(folds == f)] } # Build RF using GRF P(W = 1 | X) fun.rf.grf &lt;- function(X, W, predictkfold){ rf_grf &lt;- regression_forest(X, W, tune.parameters = &quot;all&quot;) p.grf &lt;- predict(rf_grf, predictkfold)$predictions return(p.grf) } # storing predict.mat &lt;- matrix(0, nrow = nrow(index), ncol = K) tauk &lt;- rep(0, K) tauk_oracle &lt;- rep(0, K) weighttau &lt;- rep(0, K) score &lt;- list() score_oracle &lt;- list() # for each fold i use other folds for estimation for(i in seq(1:K)){ predict.mat[, i] &lt;- fun.rf.grf(X = X[c(index[, -i]), ], W = W[index[, -i]], predictkfold = X[c(index[, i]), ]) # fold-specific treatment effect score[[i]] &lt;- ((W[index[, i]] * Y[index[, i]]) / (predict.mat[, i])) - (((1 - W[index[, i]]) * Y[index[, i]]) / (1 - predict.mat[, i])) tauk[i] &lt;- mean(score[[i]]) } # ipw using oracle propensity score and propensity score estimated from grf alpha &lt;- 0.05 # 5 percent level of significance #ipw.ranger &lt;- mean(((W * Y) / (p.ranger)) - (((1 - W) * Y) / (1 - p.ranger))) ipw.grf &lt;- mean(unlist(score)) score_oracle &lt;- ((W * Y) / (prob)) - ((1 - W) * Y / (1 - prob)) ipw.oracle &lt;- mean(score_oracle) sd.ipw &lt;- sd(unlist(score)) sd.oracle &lt;- sd(score_oracle) ll &lt;- ipw.grf - (sd.ipw / sqrt(length(unlist(score)))) * qnorm(1 - alpha/2) ul &lt;- ipw.grf + (sd.ipw / sqrt(length(unlist(score)))) * qnorm(1 - alpha/2) ll_oracle &lt;- ipw.oracle - (sd.oracle / sqrt(length(score_oracle))) * qnorm(1 - alpha/2) ul_oracle &lt;- ipw.oracle + (sd.oracle / sqrt(length(score_oracle))) * qnorm(1 - alpha/2) result.ipw &lt;- c(&quot;IPW estimate&quot; = round(ipw.grf, 3), &quot;se&quot; = round(sd.ipw / (sqrt(length(W))), 3), &quot;lower bound&quot; = round(ll, 3), &quot;upper bound&quot; = round(ul, 3)) result.oracle.ipw &lt;- c(&quot;IPW Oracle estimate&quot; = round(ipw.oracle, 3), &quot;se&quot; = round(sd.oracle / (sqrt(length(W))), 3), &quot;lower bound&quot; = round(ll_oracle, 3), &quot;upper bound&quot; = round(ul_oracle, 3)) print(result.ipw) ## IPW estimate se lower bound upper bound ## 15.508 3.092 9.448 21.568 print(result.oracle.ipw) ## IPW Oracle estimate se lower bound upper bound ## 16.496 3.165 10.294 22.699 What? Despite having true propensity score, the Oracle IPW underperforms in accuracy compared to the IPW estimate with unknown propensity score. Why is it so? "],["comparing-ipw-with-aggregated-estimate.html", "3.8 Comparing IPW with Aggregated Estimate", " 3.8 Comparing IPW with Aggregated Estimate We know that the probablity of the treatment increases with \\(X1\\), as shown below. plot(X[, 1], prob) par(new = T) abline(v = 0, col = &quot;red&quot;, lty = &quot;dashed&quot;) Next, we would want to divide \\(X1\\) into segments such that the probability of treatment remains more or less similar in each segment. Since we generated the data ourselves, we know that the probability of treatment increases for observations with \\(X1 &gt; 0\\). However, lets take 10 segments, which cuts the distribution of \\(X1\\) in decile. quant &lt;- quantile(X[, 1], p = seq(0, 1, 0.1)) group &lt;- cut(X[, 1], quant, include.lowest = TRUE) dat$group &lt;- group Next, we want to estimate the treatment effects for each segment and then aggregate it. dat_sum &lt;- data.frame(dat %&gt;% mutate(status = ifelse(W == 1, &quot;treatment&quot;, &quot;control&quot;)) %&gt;% group_by(group) %&gt;% summarize(num_treat = sum(W), n_group = n())) %&gt;% mutate(prop_treat = num_treat / n_group) %&gt;% select(c(group, prop_treat)) dat &lt;- dat %&gt;% merge(dat_sum, by = &quot;group&quot;, all.x = T) %&gt;% mutate(score = Y * ((W / prop_treat) - ((1 - W) / (1 - prop_treat))) ) paste(&quot;aggregated treatment effect is: &quot;, round(mean(dat$score), 3)) ## [1] &quot;aggregated treatment effect is: 15.019&quot; paste(&quot;se of aggregated treatment effect is: &quot;, round(sd(dat$score) / sqrt(length(W)), 3)) ## [1] &quot;se of aggregated treatment effect is: 3.122&quot; Now, let’s estimate the oracle IPW with known propensity score. score_oracle &lt;- ((W * Y) / (prob)) - ((1 - W) * Y / (1 - prob)) ipw.oracle &lt;- mean(score_oracle) se.oracle &lt;- sd(score_oracle) / sqrt(length(score_oracle)) paste(&quot;oracle IPW estimate: &quot;, round(ipw.oracle, 3)) ## [1] &quot;oracle IPW estimate: 16.496&quot; paste(&quot;standard error: &quot;, round(se.oracle, 3)) ## [1] &quot;standard error: 3.165&quot; "],["aipw-and-estimation.html", "3.9 AIPW and Estimation", " 3.9 AIPW and Estimation Augmented Inverse Probability Weighting (AIPW) provides a robust way to estimate ATE by alleviating the limitation of IPW estimate. Following the IPW approach, estimation of ATE is given in equation (6). The other approach to estimate \\(\\tau\\) is to think of it from the conditional response approach. Write \\(\\mu_{w}(x) = E[Y_i| \\; X_i = x, W_i = w]\\). Then: \\(\\tau(x) = E[Y_i| \\; X_i = x, W_i = 1] - E[Y_i| \\; X_i = x, W_i = 0]\\) This is the regression outcome approach, where \\(\\tau = E[\\mu_{1}(x) - \\mu_{0}(x)]\\). The consistent estimator can be formed by using: \\(\\hat{\\tau}(x) = N^{-1} \\sum_{i = 1}^{N} \\mu_{1}(X_i) - \\mu_{0}(X_i)\\). AIPW approach combines both IPW approach as well as regression outcome approach to estimate \\(\\tau\\). \\(\\hat{\\tau}_{AIPW} = \\frac{1}{N} \\sum_{i = 1}^{N} (\\mu_{1}(X_i) - \\mu_{0}(X_i) + \\frac{(Y_i - \\hat{\\mu}_1(X_i)). W_i}{\\hat{e}(X_i)} - \\frac{(Y_i - \\hat{\\mu}_0(X_i)). (1-W_i)}{1 - \\hat{e}(X_i)})\\) ML approach using cross-fitting is used to estimate both \\(\\hat{e}(x)\\) and \\(\\hat{\\mu}_{w}(x)\\). Following the cross-fitting structure, we can formally write the estimate for \\(\\tau\\) as: \\(\\hat{\\tau}_{AIPW} = \\lowerbracket{\\frac{1}{N} \\sum_{i = 1}^{N} (\\mu_{1}^{-k(i)}(X_i) - \\mu_{0}^{-k(i)}(X_i)}_{consistent \\; estimate \\; of \\; \\tau} + \\frac{(Y_i - \\hat{\\mu}_1^{-k(i)}(X_i)). W_i}{\\hat{e}^{-k(i)}(X_i)} - \\frac{(Y_i - \\hat{\\mu}_0^{-k(i)}(X_i)). (1-W_i)}{1 - \\hat{e}^{-k(i)}(X_i)})\\) The AIPW approach can be thought of estimating ATE taking the difference across conditional responses. Next, the residuals are adjusted using weights given by the propensity score. There are two attractive features of AIPW estimate. First, $_{AIPW} is consistent as long as \\(\\hat{e}(x)\\) or \\(\\hat{\\mu}_{w}(x)\\) is consistent. This is because \\(E[(Y_i - \\hat{\\mu}_{W_i}(X_i)) \\approx 0\\). Second, \\(\\hat{\\tau}_{AIPW}\\) is a good approximation to oracle \\(\\hat{\\tau}_{AIPW}^{*}\\) as long as \\(\\hat{\\mu}(.)\\) and \\(\\hat{e}(.)\\) are reasonably accurate. If one estimate is highly accurate, then it can compensate lack of accuracy on the other estimate. If both \\(\\hat{\\mu}(.)\\) and \\(\\hat{e}(.)\\) are \\(\\sqrt{n}\\)-consistent7, then the following holds. \\(\\sqrt{n}(\\hat{\\tau}_{AIPW} - \\hat{\\tau}_{AIPW}^{*}) \\rightarrow_p 0\\). ####################### # # Augmented IPW (aipw) # ####################### #n_features2 &lt;- length(setdiff(names(dat2), &quot;Y&quot;)) # ranger #funrf_ranger &lt;- function(dat){ # rf2 &lt;- ranger( # Y ~ ., # data = dat, # mtry = min(ceiling(sqrt(n_features) + 20), n_features), # respect.unordered.factors = &quot;order&quot;, # seed = 123, # num.trees = 2000 # ) # return(rf2) #} # storing predict.mat2a &lt;- matrix(0, nrow = nrow(index), ncol = K) predict.mat2b &lt;- predict.mat2a aipwK &lt;- rep(0, K) weightaipK &lt;- rep(nrow(index) / length(index), K) for(i in seq(1:K)){ # E(Y | X, W = 1) using cross-fitting predict.mat2a[, i] &lt;- fun.rf.grf(X = cbind(X[c(index[, -i]), ], W[index[, -i]]), W = Y[index[, -i]], predictkfold = cbind(X[c(index[, i]), ], 1)) # E(Y | X, W = 0) using cross-fitting predict.mat2b[, i] &lt;- fun.rf.grf(X = cbind(X[c(index[, -i]), ], W[index[, -i]]), W = Y[index[, -i]], predictkfold = cbind(X[c(index[, i]), ], 0)) noise &lt;- ((W[index[, i]] * (Y[index[, i]] - predict.mat2a[, i])) / (predict.mat[, i])) - (((1 - W[index[, i]]) * (Y[index[, i]] - predict.mat2b)) / (1 - predict.mat[, i])) score[[i]] &lt;- predict.mat2a[, i] - predict.mat2b[, i] + noise aipwK[i] &lt;- mean(score[[i]]) } aipw.grf &lt;- weighted.mean(aipwK, weights = weightaipK) sd.aipw &lt;- sd(unlist(score)) ll &lt;- aipw.grf - (sd.aipw / sqrt(length(unlist(score)))) * qnorm(1 - alpha/2) ul &lt;- aipw.grf + (sd.aipw / sqrt(length(unlist(score)))) * qnorm(1 - alpha/2) result.aipw &lt;- c(&quot;AIPW Est.&quot; = round(aipw.grf, 3), &quot;se&quot; = round(sd.aipw/(sqrt(length(W))), 3), &quot;lower bound&quot; = round(ll, 3), &quot;upper bound&quot; = round(ul, 3)) ###################### # grf ###################### # Train a causal forest tau.forest &lt;- causal_forest(X, Y, W) # Estimate the conditional average treatment effect on the full sample (CATE). grf_ate &lt;- average_treatment_effect(tau.forest, target.sample = &quot;all&quot;) grf_att &lt;- average_treatment_effect(tau.forest, target.sample = &quot;treated&quot;) ## PRINT ALL #print(paste0(&quot;average treatment effect is: &quot;, round(mean(pmax(X[, 1], 0)), 3))) print(paste(&quot;treatment effects according to naive estimator:&quot;, round(mean(Y[which(W == 1)]) - mean(Y[which( W == 0)]), 3), sep = &quot; &quot;)) ## [1] &quot;treatment effects according to naive estimator: 15.558&quot; print(paste(&quot;treatment effects according to IPW using&quot;, K, &quot;fold cross-fittin:&quot;, round(ipw.grf, 3), sep = &quot; &quot;)) ## [1] &quot;treatment effects according to IPW using 10 fold cross-fittin: 15.508&quot; print(paste(&quot;treatment effects according to IPW oracle:&quot;, round(ipw.oracle, 3), sep = &quot; &quot;)) ## [1] &quot;treatment effects according to IPW oracle: 16.496&quot; print(paste(&quot;treatment effects according to AIPW using&quot;, K, &quot;fold cross-fitting:&quot;, round(aipw.grf, 3), sep = &quot; &quot;)) ## [1] &quot;treatment effects according to AIPW using 10 fold cross-fitting: 15.037&quot; print(paste(&quot;treatment effects according to GRF:&quot;, round(grf_ate[[1]], 3), sep = &quot; &quot;)) ## [1] &quot;treatment effects according to GRF: 15.031&quot; print(result.ipw) ## IPW estimate se lower bound upper bound ## 15.508 3.092 9.448 21.568 print(result.aipw) ## AIPW Est. se lower bound upper bound ## 15.037 0.031 14.975 15.098 print(grf_ate) ## estimate std.err ## 15.03144837 0.05209014 This means that \\(\\hat{\\mu}(.)\\) converges to \\(\\hat{\\mu}\\) at the ↩︎ "],["assessing-balance.html", "3.10 Assessing Balance", " 3.10 Assessing Balance ########################################## # # # Assessing Balance # # ########################################## XX &lt;- X[c(index), ] YY &lt;- Y[c(index)] WW &lt;- W[c(index)] e.hat &lt;- c(predict.mat) # unadjusted means.treat &lt;- apply(XX[WW == 1, ], 2, mean) means.control &lt;- apply(XX[WW == 0, ], 2, mean) abs.mean.diff &lt;- abs(means.treat - means.control) var.treat &lt;- apply(XX[WW == 1, ], 2, var) var.control &lt;- apply(XX[WW == 0, ], 2, var) std &lt;- sqrt(var.treat + var.control) # adjusted means.treat.adj &lt;- apply(XX*WW / e.hat, 2, mean) means.control.adj &lt;- apply(XX*(1 - WW) / (1 - e.hat), 2, mean) abs.mean.diff.adj &lt;- abs(means.treat.adj - means.control.adj) var.treat.adj &lt;- apply(XX * WW / e.hat, 2, var) var.control.adj &lt;- apply(XX * (1 - WW) / (1 - e.hat), 2, var) std.adj &lt;- sqrt(var.treat.adj + var.control.adj) # plot unadjusted and adjusted differences par(oma=c(0,4,0,0)) plot(-2, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, xlim=c(-.01, 1.01), ylim=c(0, ncol(XX)+1), main=&quot;&quot;) axis(side=1, at=c(-1, 0, 1), las=1) lines(abs.mean.diff / std, seq(1, ncol(XX)), type=&quot;p&quot;, col=&quot;blue&quot;, pch=19) lines(abs.mean.diff.adj / std.adj, seq(1, ncol(XX)), type=&quot;p&quot;, col=&quot;orange&quot;, pch=19) legend(&quot;topright&quot;, c(&quot;Unadjusted&quot;, &quot;Adjusted&quot;), col=c(&quot;blue&quot;, &quot;orange&quot;), pch=19) abline(v = seq(0, 1, by=.25), lty = 2, col = &quot;grey&quot;, lwd=.5) abline(h = 1:ncol(XX), lty = 2, col = &quot;grey&quot;, lwd=.5) mtext(paste0(&quot;X&quot;, seq(1, ncol(XX))), side=2, cex=0.7, at=1:ncol(XX), padj=.4, adj=1, col=&quot;black&quot;, las=1, line=.3) abline(v = 0) hist(e.hat, breaks = 100, freq = FALSE) "],["cross-fitting.html", "3.11 Cross-fitting", " 3.11 Cross-fitting What is cross-fitting? Divide the data into K folds randomly. Train the model using \\(-k\\) folds (all folds except the \\(k^{th}\\) one). Generate a fit of fold k on the model trained using \\(-k\\) folds Repeat steps 2 and 3 to generate fit for all \\(K\\) number of folds. This is illustrated using the figure below. The data is randomly divided into 5 folds (segments). This is an example of a five-fold cross-fitting. In the first round, the blue segments are used for model building, while responses are constructed for observations in the green segment of the data. Next, we move into the second round and so on; again the blue segments are used for model building and responses are constructed for the green segment. In this way, each observation is used for model building. # cross-fitting illustration colorcode &lt;- diag(5) # this creates a coding colorcode &lt;- c(colorcode) # Create data for the boxes boxes &lt;- data.frame( x = rep(seq(2, 10, 2), 5), y = rep(seq(5, 1, by = -1), each = 5), label = rep(paste(&quot;fold&quot;, seq(1, 5), sep = &quot; &quot;), 5), colorcode = colorcode ) boxes &lt;- boxes %&gt;% mutate(fill = ifelse(colorcode == 1, &quot;lightgreen&quot;, &quot;lightblue&quot;)) %&gt;% select(-c(colorcode)) # Create the plot ggplot() + geom_rect(data = boxes, aes(xmin = x , xmax = x + 2, ymin = y - 0.3, ymax = y + 0.5, fill = fill), color = &quot;black&quot;, alpha = 0.5) + xlim(0, 14) + ylim(-1, 6) + theme_void() + scale_fill_identity() + annotate(&quot;text&quot;, x = c(seq(3, 11, 2), rep(0.5, 5)), y = c(rep(0.3, 5), seq(5, 1, -1)), label = c(paste(&quot;fold&quot;, seq(1, 5, 1), sep = &quot; &quot;), paste(&quot;round&quot;, seq(1, 5, 1), sep = &quot; &quot;)), color = rep(c(&quot;red&quot;, &quot;black&quot;), each = 5) ) What does it do? Simply put, cross-fitting assures that the same observations are not used for modeling building as well as to estimate the response (e.g., predictions). In this way, we would want to alleviate concerns of over-fitting. "],["causal-forest.html", "4 Causal Forest ", " 4 Causal Forest "],["introduction.html", "4.1 Introduction", " 4.1 Introduction The generalized random forest is a method that is quite flexible in estimating the quantity of interest. The theory of it is built using the moment criterion: \\(E[\\psi_{\\theta_i, \\; \\upsilon_i} (O_i) | X_i] = 0, \\; for \\; all \\; x \\; in \\; \\chi\\) Getting down to the nuts and bolts of the theory is beyond the scope of this write-up. Rather, we would want to take a closer look at causal forests – a component of GRF framework. "],["summary-of-grf.html", "4.2 Summary of GRF", " 4.2 Summary of GRF It seeks a generalized way to conduct causal inference under a non-parametric framework. GRF relies on random forest. Methods developed to aid causal inference such as: \\(i)\\) randomized controlled trial, \\(ii)\\) comparison between treatment and control units under unconfoundedness assumption, \\(iii)\\) difference-in-differences, and \\(iv)\\) panel data methods; can fit into GRF framework. To do so, one needs to feed in the method-specific encoding into the GRF framework (to guide the splitting process). "],["motivation-for-causal-forests.html", "4.3 Motivation for Causal Forests", " 4.3 Motivation for Causal Forests Let’s expand on estimating the average treatment effect of a treatment intervention \\(W\\). The specifics are listed as: \\(W_i \\in \\{0, \\; 1\\}\\): treatment intervention \\(X_i\\): covariates \\(Y_i\\): response/outcome In the parametric framework \\(\\tau\\), the treatment effect, is estimated using the following specification: \\(Y_i = \\tau W_i + \\beta_1 X_i + \\epsilon_i\\) The validity of \\(\\hat{\\tau}\\) as a causal estimand is justified under the following three assumptions. Unconfoundedness: \\(Y^{(0)}_i, \\; Y^{(1)}_i \\perp W_i | X_i\\). Treatment assignment is independent of the potential outcome once conditioned on the covariates. In other words, controling for covariates makes the treatment assignment as good as random. \\(X_i\\)s influence \\(Y_i\\)s in a linear way. The treatment effect is homogeneous. Assumption 1 is the identification assumption. In the traditional sense, one can control for \\(X_i\\)s in the regression framework and argue that this assumption is met. Even if all \\(X\\)s that influence the treatment assignment are observed (this is the assumption that we make throughout), we are unsure how \\(X\\)s affect the treatment. Often \\(X\\)s can affect treatment in a non-linear way. Assumptions 2 and 3 can be questioned and relaxed. One can let data determine the way \\(X\\) needs to be incorporated in the model specification (relaxing assumption 2). Moreover, treatment effects can vary across some covariates (relaxing assumption 3). First, lets relax assumption 2. This leads to the following partially linear model: \\(Y_i = \\tau W_i + f(X_i) + \\epsilon_i \\;............. equation 1\\) where, \\(f\\) is a function that maps out how \\(X\\) affects \\(Y\\). However, we don’t know \\(f\\) in practice. So, how do we go about estimating \\(\\tau\\)? The causal forest framework under GRF connects the old-school literature of causal inference with ML methods. Robinson (1988) shows that if two intermediate (nuiscance) objects, \\(e(X_i)\\) and \\(m(X_i)\\) are known, one can estimate \\(\\tau\\). The causal forest framework under GRF utilizes this result. Here: \\(e(X_i)\\) is the propensity score; the probability of being treated. \\(E[W_i| X_i = x]\\) \\(m(X_i)\\) is the conditional mean of \\(Y\\). \\(E[Y_i | X_i = x] = f(x) + \\tau e(x)\\) Demeaning equation 1 (substracting \\(m(x)\\)) gives the following residual-on-residual regression: \\(Y_i - m(x) = \\tau (W_i - e(x)) + \\epsilon \\; .............. equation 2\\) Intuition for equation (2) proceeds as follow. Note that \\(m(x)\\) is the conditional mean of Y given \\(X_i = x\\).8 This means that units with similar \\(X\\)s will have similar estimates for \\(m(x)\\) in \\(W=\\{0, \\; 1\\}\\), which would mean that estimates on \\(e(x)\\) would also be similar for these units across both treatment and control group. Now, consider that the treatment is positive; this will show up in \\(Y_i\\). \\(Y_i - m(x)\\) will be higher for \\(W=1\\) compared to \\(W=0\\) for similar estimates of \\(m(x)\\). On the other side, \\(W_i - e(x)\\) is positive for \\(W=1\\) and negative for \\(W=0\\) for similar estimates of \\(e(x)\\). Such variations in the left and right hand side quantities will allow to capture postive estimates on \\(\\tau\\). To gain ML methods are used to estimate \\(m(x)\\) and \\(e(x)\\) and residual-on-residual regression is used estimate \\(\\tau\\). It turns out that even noisy estimates of \\(e(x)\\) and \\(m(x)\\) can give ``ok” estimate of \\(\\tau\\). How to estimate \\(m(x)\\) and \\(e(x)\\)? Use ML methods (boosting; random forest) Use cross-fitting for prediction. prediction of observation \\(i&#39;s\\) outcome &amp; treatment assignment is obtained without using the observation ``\\(i\\)“. Lets take a look at residual-on-residual in the case of homogeneous treatment effect. # generate data n &lt;- 2000 p &lt;- 10 X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) # Generate W and Y W &lt;- rbinom(n, 1, 0.4 + 0.2 * (X[, 1] &gt; 0)) prob &lt;- 0.4 + 0.2 * (X[, 1] &gt; 0) Y &lt;- 2.5 * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n) # Train regression forests mx &lt;- regression_forest(X, Y, tune.parameters = &quot;all&quot;) ex &lt;- regression_forest(X, W, tune.parameters = &quot;all&quot;) Wcen &lt;- W - ex$predictions Ycen &lt;- Y - mx$predictions reg &lt;- summary(lm(Ycen ~ Wcen)) reg ## ## Call: ## lm(formula = Ycen ~ Wcen) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6687 -0.7147 -0.0139 0.7059 3.9119 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.00539 0.02359 -0.228 0.819 ## Wcen 2.45817 0.04791 51.305 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.055 on 1998 degrees of freedom ## Multiple R-squared: 0.5685, Adjusted R-squared: 0.5683 ## F-statistic: 2632 on 1 and 1998 DF, p-value: &lt; 2.2e-16 print(paste0(&quot;The treatment effect estimate based on residual-on-residual regression is: &quot;, coefficients(reg)[2])) ## [1] &quot;The treatment effect estimate based on residual-on-residual regression is: 2.45817277748273&quot; print(paste0(&quot;The true treatment effect is: &quot;, 2.5)) ## [1] &quot;The true treatment effect is: 2.5&quot; We can also think of \\(m(x)\\) as the case when we ignore \\(W\\), although we know that treatment took place. This way, \\(m(x) = \\mu_{0}(x) + e(x)\\tau\\), where \\(\\mu_{0}(x)\\) is the baseline conditional expectation without the treatment. This makes it easy to see that units with similar features will have similar estimates of \\(m(x)\\).↩︎ "],["causal-forest-1.html", "4.4 Causal Forest", " 4.4 Causal Forest Both regression and causal forests consist of: 1) Building phase; and 2) estimation phase. The intuition regarding the regression/causal forest can be gleaned using the following figure. Figure 4.1: Figure 1. Adaptive weights In this simple case, the sample is partitioned into \\(N_1\\) and \\(N_2\\) neighborhoods accorinng to the splitting rule that the squared difference in sub-sample specific treatment effect is the maximum, i.e., \\(n_{N_1}n_{N_2}(\\tau_{N_1} - \\tau_{N_2})^2\\) is the maximum. This by construction leads to constant treatment effect in the neighborhood, while the effects may vary across the neighborhoods. This intuition allows us to relax assumption 3, and re-write the partially linear estimation framework as: \\(Y_i = \\tau(x) W_i + f(X_i) + \\epsilon_i\\). Here the estimate of the treatment effect \\(\\tau\\) is allowed to vary with the test point \\(x\\). In reference to Figure 1 above, \\(N_1\\) and \\(N_2\\) are neighborhoods where treatment effects are constant. To estimate the treatment effect of the test point \\(x\\), \\(\\tau(x)\\), we would run a weighted residual-on-residual regression of the form. \\(\\tau(x) := lm(Y_i - m(X_i)^{-i} \\sim \\tau(W_i - e(X_i)^{-i}), \\; weights = 1\\{X_i \\in N(x)\\}\\) where \\(m(X_i)^{-i}\\) and \\(e(X_i)^{-i}\\) are obtained from cross-fitting. The weights play a pivotal role here and takes a value 1 if \\(X_i\\) belongs to the same neighborhoods as \\(x\\). In the above figure, examples in \\(N_2\\) receive non-zero weight while those in \\(N_1\\) receive zero weight. However, this example only pertains to a tree. But we’d want to build a forest and apply the same analogy. Adaptive weights. The forest consists of \\(B\\) trees, so the weights for each \\(X_i\\) pertaining to the test point \\(x\\) is based off of all \\(B\\) trees. The causal forest utilizes adaptive weights using random forests. The tree specific weight for an example \\(i\\) at the \\(b^{th}\\) tree is given as: \\(\\alpha_{ib}(x) = \\frac{1(X_i \\in L_{b}(x))}{|L_{b}(x)|}\\), where \\(L(x)\\) is the leaf (neighborhood) that consist of the test sample \\(x\\). The forest specific weight for an example \\(i\\) is given as: \\(\\alpha_{i}(x) = \\frac{1}{B} \\sum_{b = 1}^{B} \\frac{1(X_i \\in L(x))}{|L(x)|}\\) It tracks the fraction of times an obsevation \\(i\\) falls on the same leaf as \\(x\\) in the course of the forest. Simply, it shows how similar \\(i\\) is to \\(x\\). Regression Forest. It utilizes the adaptive weights given to an example \\(i\\) (\\(i = \\{1, \\; 2, \\; ..., N\\}\\)) and constructs a weighted average to form the prediction of \\(x\\). The prediction for \\(x\\) based on the regression forest is: \\(\\hat{\\mu}(x) = \\frac{1}{B}\\sum_{i = 1}^{N} \\sum_{b=1}^{B} Y_{i} \\frac{1(X_i \\in L_{b}(x)}{|L_b(x)|}\\) \\(= \\sum_{i = 1}^{N} Y_{i} \\alpha_{i}\\) Note that this is different from the traditional prediction from the random forest that averages predictions from each tree. \\(\\hat{\\mu}(x.trad) = \\sum_{b = 1}^{B} \\frac{\\hat{Y}_b}{B}\\) Causal Forest. Causal forest is analogous to the regression forest in a sense that the target is \\(\\tau(x)\\) rather than \\(\\mu(x)\\). Conceptually the difference is encoded in the splitting criteria. While splitting, regression forest is based on the criterion: \\(\\max n_{N_1} n_{N_2}(\\mu_{N_1} - \\mu_{N_2})^2\\), whereas the causal forest is based on \\(\\max n_{N_1} n_{N_2}(\\tau_{N_1} - \\tau_{N_2})^2\\). In a world with infinite computing power, for each potential axis aligned split that extends from the parent node, one would estimate treatment effects at two of the child nodes (\\(\\tau_{L}\\) and \\(\\tau_{R}\\)) and go for the split that maximizes the squared difference between child specific treatment effects. However, in practice this is highly computationally demanding and infeasible. The application of causal forest estimates \\(\\tau_{P}\\) at the parent node and uses the gradient based function to guide the split. At each (parent) node the treatment effect is estimated only once. Once the vector of weights are determined for \\(i\\)s, the following residual-on-residual is ran: \\(\\tau(x) := lm(Y_i - m(X_i^{-i}) \\sim \\tau(x)(W_i - e(X_i)^{-i}), \\; weights = \\alpha_i(x)\\) This can be broken down as: Estimate \\(m^{-i}(X_i)\\) and \\(e^{-i}(X_i)\\) using random forest. Then estimate \\(\\alpha_i(x)\\). For each new sample point \\(x\\), a vector of weight will be determined based on adaptive weighting scheme of the random forest. Note that the weights will change for each new test point. Run a weighted residual-on-residual regression given by the equation above. "],["an-example-of-causal-forest.html", "4.5 An example of causal forest", " 4.5 An example of causal forest rm(list = ls()) library(devtools) ## Loading required package: usethis #devtools::install_github(&quot;grf-labs/grf&quot;, subdir = &quot;r-package/grf&quot;) library(grf) library(ggplot2) # generate data n &lt;- 2000 p &lt;- 10 X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) # Train a causal forest. W &lt;- rbinom(n, 1, 0.4 + 0.2 * (X[, 1] &gt; 0)) Y &lt;- pmax(X[, 1], 0) * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n) # Train a causal forest c.forest &lt;- causal_forest(X, Y, W) # predict using the training data using out-of-bag prediction tau.hat.oob &lt;- predict(c.forest) hist(tau.hat.oob$predictions) # Estimate treatment effects for the test sample tau.hat &lt;- predict(c.forest, X.test) plot(X.test[, 1], tau.hat$predictions, ylim = range(tau.hat$predictions, 0, 2), xlab = &quot;x&quot;, ylab = &quot;tau&quot;, type = &quot;l&quot;) lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2) # estimate conditional average treatment effect (CATE) on the full sample cate &lt;- average_treatment_effect(c.forest, target.sample = &quot;all&quot;) print(paste(&quot;Conditinal Average Treatment Effect (CATE) is: &quot;, cate[[1]])) ## [1] &quot;Conditinal Average Treatment Effect (CATE) is: 0.405843073161648&quot; # estimate conditional average treatment effect on treated catt &lt;- average_treatment_effect(c.forest, target.sample = &quot;treated&quot;) paste(&quot;Conditional Average Treatment Effect on the Treated (CATT)&quot;, catt[[1]]) ## [1] &quot;Conditional Average Treatment Effect on the Treated (CATT) 0.492339168239352&quot; # Add confidence intervals for heterogeneous treatment effects; growing more trees recommended tau.forest &lt;- causal_forest(X, Y, W, num.trees = 4000) tau.hat &lt;- predict(tau.forest, X.test, estimate.variance = TRUE) # for the test sample ul &lt;- tau.hat$predictions + 1.96 * sqrt(tau.hat$variance.estimates) ll &lt;- tau.hat$predictions - 1.96 * sqrt(tau.hat$variance.estimates) tau.hat$ul &lt;- ul tau.hat$ll &lt;- ll tau.hat$X.test &lt;- X.test[,1] ggplot(data = tau.hat, aes(x = X.test, y = predictions)) + geom_ribbon(aes(ymin = ll, ymax = ul), fill = &quot;grey70&quot;) + geom_line(aes(y = predictions)) + theme_bw() ###################################################### # # # In some cases prefitting Y and W separately may # be helpful. Say they use different covariates. # ###################################################### # Generate a new data n &lt;- 4000 p &lt;- 20 X &lt;- matrix(rnorm(n * p), n, p) TAU &lt;- 1 / (1 + exp(-X[, 3])) W &lt;- rbinom(n, 1, 1 / (1 + exp(-X[, 1] - X[, 2]))) # X[, 1] and X[, 2] influence W Y &lt;- pmax(X[, 2] + X[, 3], 0) + rowMeans(X[, 4:6]) / 2 + W * TAU + rnorm(n) # X[, 2], X[, 3], X[, 4:6] influence Y. So different set of Xs influence Y # Build a separate forest for Y and W forest.W &lt;- regression_forest(X, W, tune.parameters = &quot;all&quot;) W.hat &lt;- predict(forest.W)$predictions # this gives us the estimated propensity score (probability of treated) #plot(W.hat, X[, 1], col = as.factor(W)) #plot(W.hat, X[, 2], col = as.factor(W)) forest.Y &lt;- regression_forest(X, Y, tune.parameters = &quot;all&quot;) # note that W is not used here Y.hat &lt;- predict(forest.Y)$predictions # this gives the conditional mean of Y or m(x) #plot(Y, Y.hat) forest.Y.varimp &lt;- variable_importance(forest.Y) forest.Y.varimp ## [,1] ## [1,] 0.002939109 ## [2,] 0.464324588 ## [3,] 0.386426876 ## [4,] 0.040967280 ## [5,] 0.025417033 ## [6,] 0.053186112 ## [7,] 0.002563865 ## [8,] 0.001711964 ## [9,] 0.001464095 ## [10,] 0.001727238 ## [11,] 0.002546653 ## [12,] 0.001280970 ## [13,] 0.002841205 ## [14,] 0.002328143 ## [15,] 0.001422961 ## [16,] 0.001131292 ## [17,] 0.001542447 ## [18,] 0.002144746 ## [19,] 0.002829431 ## [20,] 0.001203992 # selects the important variables selected.vars &lt;- which(forest.Y.varimp / mean(forest.Y.varimp) &gt; 0.2) selected.vars ## [1] 2 3 4 5 6 # Trains a causal forest tau.forest &lt;- causal_forest(X[, selected.vars], Y, W, W.hat = W.hat, Y.hat = Y.hat, # specify e(x) and m(x) tune.parameters = &quot;all&quot;) # See if a causal forest succeeded in capturing heterogeneity by plotting # the TOC and calculating a 95% CI for the AUTOC. train &lt;- sample(1:n, n / 2) train.forest &lt;- causal_forest(X[train, ], Y[train], W[train]) eval.forest &lt;- causal_forest(X[-train, ], Y[-train], W[-train]) rate &lt;- rank_average_treatment_effect(eval.forest, predict(train.forest, X[-train, ])$predictions) rate ## estimate std.err target ## -0.002787873 0.04889062 priorities | AUTOC plot(rate) paste(&quot;AUTOC:&quot;, round(rate$estimate, 2), &quot;+/&quot;, round(1.96 * rate$std.err, 2)) ## [1] &quot;AUTOC: 0 +/ 0.1&quot; "],["heterogeneous-treatment-effects.html", "5 Heterogeneous Treatment Effects", " 5 Heterogeneous Treatment Effects This article summarizes heterogeneous treatment effects using ML. Simply put, its defined as the variation in response to treatment across several subgroups. For example, the impacts of Medicaid expansion on labor market outcomes can vary depending on uninsured rate prior to the expansion; the effects of discussion intervention program aimed to normalize disscussion regarding menstruation can increase demand for menstrual health products at a higher rate among those with high psychological cost in the baseline; in personalized medical treatment, we would want to identify the sub-group with higher response to a particular type of treatment. It is different from average treatment effect (ATE) such that the ATE focuses on the whole group, while heterogeneous treatment effect pertains to the specific sub-group characterized by features (\\(X\\)s). In this sense, one can think of ATE as the weighted average of subgroup specific ATEs. Using the potential outcome framework, ATE is given by: \\(E[Y_i^{1} - Y_i^{0}]\\). The heterogeneous treatment is: \\(E[Y_i^{1} - Y_i^{0} | X_i = x ]\\). Its the treatment conditional on \\(X_i\\), which is determined prior to observing the data. Hence, its also termed as the conditional average treatment effect (CATE). One simple example borrowed from Wager’s lecture notes to illustrate the concept is that of smoking in Geneva and Palo Alto. Say, two RCTs are conducted in Palo Alto and Geneva to evaluate whether cash incentives among teenagers can reduce the prevalence of smoking. # Palo-Alto smoke_mat &lt;- function(smoke_vec){ smoke &lt;- matrix(0, nrow =2, ncol = 3) smoke[, 1] &lt;- c(&quot;Treat&quot;, &quot;Control&quot;) smoke[ ,2] &lt;- c(smoke_vec[1], smoke_vec[2]) smoke[ ,3] &lt;- c(smoke_vec[3], smoke_vec[4]) return(smoke) } smoke &lt;- smoke_mat(c(152, 2362, 5, 122)) colnames(smoke) &lt;- c(&quot;Palo Alto&quot;, &quot;Non-S.&quot;, &quot;Smoker&quot;) data.frame(smoke) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) Palo.Alto Non.S. Smoker Treat 152 5 Control 2362 122 smoke &lt;- smoke_mat(c(581, 2278, 350, 1979)) colnames(smoke) &lt;- c(&quot;Geneva&quot;, &quot;Non-S.&quot;, &quot;Smoker&quot;) data.frame(smoke) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) Geneva Non.S. Smoker Treat 581 350 Control 2278 1979 \\(\\hat{\\tau}_{PA} = \\frac{5}{152+5} - \\frac{122}{2362 + 122} \\approx -1.7 pp\\) \\(\\hat{\\tau}_{GVA} = \\frac{350}{581+350} - \\frac{1979}{2278 + 1979} \\approx -8.9 pp\\) \\(\\hat{\\tau} = \\frac{2641}{2641 + 5188}\\tau_{PA} + \\frac{5188}{2641 + 5188}\\tau_{GVA}\\). Here, \\(\\hat{\\tau}_{PA}\\) is an estimate of \\(E[smoke \\;prevalence | \\; W = 1, \\; X = PA] \\; - \\; E[smoke \\;prevalence | \\; W = 0, \\; X = PA]\\), and its the treatment effect particular to Palo Alto. The average treatment effect \\(\\hat{\\tau}\\) is the weighted average of the two treatment effects. "],["some-ways-to-estimate-cate.html", "5.1 Some ways to estimate CATE", " 5.1 Some ways to estimate CATE Robinson’s partially linear model for homogeneous treatment effect is written as: \\(Y_i = \\tau W_i + f(X_i) + \\epsilon_i \\; ........(equation \\; 1)\\) Here, \\(\\tau\\) is assumed constant across sub-spaces of \\(X\\). We can expand to write Robinson’s partially linear model as: \\(Y_i = \\tau(X_i) W_i + f(X_i) + \\epsilon_i \\; ........(equation \\; 2)\\) where, \\(\\tau(.)\\) varies with \\(x\\). Equation 2 can be expressed as residual-on-residual regression format of: \\(Y_i - m(X_i) = \\tau(X_i) (W_i - e(X_i)) + \\epsilon_i \\; ........(equation \\; 3)\\) where, \\(m(x)\\) is the conditional expectation of \\(Y\\) given \\(X\\). \\(m(x) = E[Y_i | \\; X_i = x] = \\mu_{W = 0}(X_i) + \\tau(X_i) e(X_i)\\), where \\(\\mu_{0}(X_i)\\) is the baseline conditional response (in absense of treatment) and \\(e(x) = P(W_i = 1 | \\; X_i = x)\\).9 \\(\\tau(X)\\) is parameterized as \\(\\tau(x) = \\psi(x).\\beta\\), where \\(\\psi\\) is some pre-determined set of basis functions: \\(\\chi \\rightarrow R^k\\). A feasible loss function can be devised using equation 3 and using estimates of \\(m(x)\\) and \\(e(x)\\) from cross-fitting. \\(L = \\frac{1}{n} \\sum_{i = 1}^n((Y_i - \\hat{m}(X_i)^{-k(i)}) - (W_i - \\hat{e}(X_i)^{-k(i)}) \\; \\psi(X_i).\\beta)^2\\). Note that the parameter of interest is \\(\\beta\\). LASSO can be used to estimate \\(\\hat{\\beta}\\), where: \\(\\hat{\\beta} = argmin_{\\beta}\\{L + \\lambda \\; ||\\beta||_{1}\\}\\), where \\(\\lambda\\) is the regularizer on the complexity of \\(\\tau(.)\\).10 Note: The other approach is to use random forest to measure out weight of an observation \\(i\\) in relation to the test point \\(x\\). This approach is done using causal forest in the Generalized Random Forest framework. The distinction between \\(m(x)\\) and \\(m(X_i)\\) is such that the former is estimation performed at the new data point \\(x\\).↩︎ One can build a highly complex model and improve the in-sample fit. However, this model may perform badly while predicting out-of-sample cases. As such, the complexity of the model should be penalized while training the model.↩︎ "],["estimation.html", "5.2 Estimation", " 5.2 Estimation set.seed(194) # Generate Data n &lt;- 2000 p &lt;- 10 X &lt;- matrix(rnorm(n * p), n, p) X.test &lt;- matrix(0, 101, p) X.test[, 1] &lt;- seq(-2, 2, length.out = 101) W &lt;- rbinom(n, 1, 0.4 + 0.2 * (X[, 1] &gt; 0)) prob &lt;- 0.4 + 0.2 * (X[, 1] &gt; 0) Y &lt;- pmax(X[, 1], 0) * W + X[, 2] + pmax(X[, 3], 0) + rnorm(n) ################################### ################################### # # # 1. estimate m(X) and e(X) # using cross-fitting # ################################### ################################### # cross-fitting index K &lt;- 10 # total folds ind &lt;- sample(1:length(W), replace = FALSE, size = length(W)) folds &lt;- cut(1:length(W), breaks = K, labels = FALSE) index &lt;- matrix(0, nrow = length(ind) / K, ncol = K) for(f in 1:K){ index[, f] &lt;- ind[which(folds == f)] } # Build a function to estimate conditional means (m(x) and e(x)) using random forest fun.rf.grf &lt;- function(X, Y, predictkfold){ rf_grf &lt;- regression_forest(X, Y, tune.parameters = &quot;all&quot;) p.grf &lt;- predict(rf_grf, predictkfold)$predictions return(p.grf) } # storing predict.mat &lt;- matrix(0, nrow = nrow(index), ncol = K) # to store e(x) predict.mat2 &lt;- predict.mat # to store m(x) # for each fold k use other folds for estimation for(k in seq(1:K)){ predict.mat[, k] &lt;- fun.rf.grf(X = X[c(index[, -k]), ], Y = W[index[, -k]], predictkfold = X[c(index[, k]), ]) predict.mat2[, k] &lt;- fun.rf.grf(X = X[c(index[, -k]), ], Y = Y[c(index[, -k])], predictkfold = X[c(index[, k]), ]) } W.hat &lt;- c(predict.mat) Y.hat &lt;- c(predict.mat2) ################################ ################################ # # 2. Use LASSO to minimize # the loss function ################################ ################################ # rearrange features and response according to index XX &lt;- X[c(index), ] YY &lt;- Y[c(index)] WW &lt;- W[c(index)] resid.Y &lt;- YY - Y.hat resid.W &lt;- WW - W.hat # Create basis expansion of features for(i in seq(1, ncol(XX))) { if(i == 1){ XX.basis &lt;- bs(XX[, i], knots = c(0.25, 0.5, 0.75), degree = 2) }else{ XX.basisnew &lt;- bs(XX[, i], knots = c(0.25, 0.5, 0.75), degree = 2) XX.basis &lt;- cbind(XX.basis, XX.basisnew) } } resid.W.X &lt;- resid.W * XX.basis resid.W.X &lt;- model.matrix(formula( ~ 0 + resid.W.X)) #plot(XX[ ,1], pmax(XX[ , 1], 0)) # cross validation for lasso to tune lambda lasso &lt;- cv.glmnet( x = resid.W.X, y = resid.Y, alpha = 1, intercept = FALSE ) #plot(lasso, main = &quot;Lasso penalty \\n \\n&quot;) # lambda with minimum MSE best.lambda &lt;- lasso$lambda.min lasso_tuned &lt;- glmnet( x = resid.W.X, y = resid.Y, lambda = best.lambda, intercept = FALSE ) #print(paste(&quot;The coefficients of lasso tuned are:&quot;, coef(lasso_tuned), sep = &quot; &quot;)) pred.lasso &lt;- predict(lasso, newx = XX.basis) ######################### # # Causal Forest # ######################### X.test &lt;- matrix(0, nrow = nrow(X), ncol = ncol(X)) X.test[, 1] &lt;- seq(-3, 3, length.out = nrow(X)) tau.forest &lt;- causal_forest(X, Y, W) tau.forest ## GRF forest object of type causal_forest ## Number of trees: 2000 ## Number of training samples: 2000 ## Variable importance: ## 1 2 3 4 5 6 7 8 9 10 ## 0.707 0.045 0.030 0.037 0.034 0.029 0.026 0.035 0.024 0.033 tau.hat &lt;- predict(tau.forest, X.test)$predictions par(oma=c(0,4,0,0)) plot(XX[order(XX[ , 1]), 1], pred.lasso[order(XX[, 1])], ylim = c(0, 3), t = &quot;l&quot;, xlab = &quot; &quot;, ylab = &quot; &quot;, xlim = c(-3, 3), lwd = 1.5) par(new = TRUE) plot(XX[order(XX[, 1]), 1], pmax(XX[order(XX[, 1]), 1], 0), col =&quot;red&quot;, ylim = c(0, 3), t = &quot;l&quot;, xlab = &quot;X1&quot;, ylab = &quot;tao(x)&quot;, xlim = c(-3, 3), lwd = 1.5) par(new = TRUE) plot(X.test[order(X.test[, 1]), 1], tau.hat[order(X.test[, 1])], t = &quot;l&quot;, col = &quot;blue&quot;, ylim = c(0, 3), xlab = &quot;X1&quot;, ylab = &quot;&quot;, xlim = c(-3, 3), lwd = 1.5) legend(&quot;topleft&quot;, c(&quot;Loss min Lasso&quot;, &quot;True Effect&quot;, &quot;Causal Forest&quot;), col = c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;), lty = rep(1, 3)) "],["some-remarks-and-questions.html", "5.3 Some Remarks and Questions", " 5.3 Some Remarks and Questions For LASSO, we are using the basis of polynomial splines of degree 2 with interior knots at 25th, 75th, and 50th percentiles of each feature. We can see that although the effects are picked up, its slightly late and are lower compared to the true effect. A basis for linear splines performs well in this case. The causal forest framework on the other hand performs better. "]]
