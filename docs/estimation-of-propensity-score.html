<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.4 Estimation of propensity score | Causal Inference</title>
  <meta name="description" content="7.4 Estimation of propensity score | Causal Inference" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="7.4 Estimation of propensity score | Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.4 Estimation of propensity score | Causal Inference" />
  
  
  

<meta name="author" content="Vinish Shrestha" />


<meta name="date" content="2026-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="propensity-score.html"/>
<link rel="next" href="using-cross-fitting-to-predict-propensity-score.html"/>
<script src="assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="assets/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="assets/kePrint-0.0.1/kePrint.js"></script>
<link href="assets/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="a-lab-experiment.html"><a href="a-lab-experiment.html"><i class="fa fa-check"></i><b>2.1</b> A lab experiment</a></li>
<li class="chapter" data-level="2.2" data-path="challenges.html"><a href="challenges.html"><i class="fa fa-check"></i><b>2.2</b> Challenges</a></li>
<li class="chapter" data-level="2.3" data-path="dag-directed-acyclic-graph.html"><a href="dag-directed-acyclic-graph.html"><i class="fa fa-check"></i><b>2.3</b> DAG (Directed Acyclic Graph)</a></li>
<li class="chapter" data-level="2.4" data-path="a-simulated-dgp.html"><a href="a-simulated-dgp.html"><i class="fa fa-check"></i><b>2.4</b> A simulated DGP</a></li>
<li class="chapter" data-level="2.5" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>2.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="why-regression.html"><a href="why-regression.html"><i class="fa fa-check"></i><b>3</b> Why Regression?</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-best-fit-line.html"><a href="the-best-fit-line.html"><i class="fa fa-check"></i><b>3.1</b> The best-fit line</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regression-specification.html"><a href="linear-regression-specification.html"><i class="fa fa-check"></i><b>3.2</b> Linear Regression Specification</a></li>
<li class="chapter" data-level="3.3" data-path="law-of-iterated-expectation.html"><a href="law-of-iterated-expectation.html"><i class="fa fa-check"></i><b>3.3</b> Law of iterated expectation</a></li>
<li class="chapter" data-level="3.4" data-path="error-term.html"><a href="error-term.html"><i class="fa fa-check"></i><b>3.4</b> Error term</a></li>
<li class="chapter" data-level="3.5" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>3.5</b> Decomposition</a></li>
<li class="chapter" data-level="3.6" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>3.6</b> Estimation</a></li>
<li class="chapter" data-level="3.7" data-path="running-a-regression.html"><a href="running-a-regression.html"><i class="fa fa-check"></i><b>3.7</b> Running a regression</a></li>
<li class="chapter" data-level="3.8" data-path="standard-errors.html"><a href="standard-errors.html"><i class="fa fa-check"></i><b>3.8</b> Standard Errors</a></li>
<li class="chapter" data-level="3.9" data-path="an-exercise.html"><a href="an-exercise.html"><i class="fa fa-check"></i><b>3.9</b> An exercise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regression-and-gradient-descent.html"><a href="regression-and-gradient-descent.html"><i class="fa fa-check"></i><b>4</b> Regression and Gradient Descent</a></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic regression</a></li>
<li class="chapter" data-level="6" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>6</b> Causal Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="potential-outcome-framework-neyman-rubin-causal-model.html"><a href="potential-outcome-framework-neyman-rubin-causal-model.html"><i class="fa fa-check"></i><b>6.1</b> Potential Outcome Framework: Neyman-Rubin Causal Model</a></li>
<li class="chapter" data-level="6.2" data-path="average-treatment-effect-ate.html"><a href="average-treatment-effect-ate.html"><i class="fa fa-check"></i><b>6.2</b> Average treatment effect (ATE)</a></li>
<li class="chapter" data-level="6.3" data-path="rct.html"><a href="rct.html"><i class="fa fa-check"></i><b>6.3</b> RCT</a></li>
<li class="chapter" data-level="6.4" data-path="average-treatment-effect-on-the-treated-att.html"><a href="average-treatment-effect-on-the-treated-att.html"><i class="fa fa-check"></i><b>6.4</b> Average treatment effect on the treated (ATT)</a></li>
<li class="chapter" data-level="6.5" data-path="an-estimation-example.html"><a href="an-estimation-example.html"><i class="fa fa-check"></i><b>6.5</b> An estimation example</a></li>
<li class="chapter" data-level="6.6" data-path="unconfoundedness-assumption.html"><a href="unconfoundedness-assumption.html"><i class="fa fa-check"></i><b>6.6</b> Unconfoundedness assumption</a></li>
<li class="chapter" data-level="6.7" data-path="discussion-1.html"><a href="discussion-1.html"><i class="fa fa-check"></i><b>6.7</b> Discussion</a></li>
<li class="chapter" data-level="6.8" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>6.8</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ipw-and-aipw.html"><a href="ipw-and-aipw.html"><i class="fa fa-check"></i><b>7</b> IPW and AIPW</a>
<ul>
<li class="chapter" data-level="7.1" data-path="a-simple-example.html"><a href="a-simple-example.html"><i class="fa fa-check"></i><b>7.1</b> A simple example</a></li>
<li class="chapter" data-level="7.2" data-path="aggregated-estimator.html"><a href="aggregated-estimator.html"><i class="fa fa-check"></i><b>7.2</b> Aggregated Estimator</a></li>
<li class="chapter" data-level="7.3" data-path="propensity-score.html"><a href="propensity-score.html"><i class="fa fa-check"></i><b>7.3</b> Propensity score</a></li>
<li class="chapter" data-level="7.4" data-path="estimation-of-propensity-score.html"><a href="estimation-of-propensity-score.html"><i class="fa fa-check"></i><b>7.4</b> Estimation of propensity score</a></li>
<li class="chapter" data-level="7.5" data-path="using-cross-fitting-to-predict-propensity-score.html"><a href="using-cross-fitting-to-predict-propensity-score.html"><i class="fa fa-check"></i><b>7.5</b> Using cross-fitting to predict propensity score</a></li>
<li class="chapter" data-level="7.6" data-path="propensity-score-stratification.html"><a href="propensity-score-stratification.html"><i class="fa fa-check"></i><b>7.6</b> Propensity score stratification</a></li>
<li class="chapter" data-level="7.7" data-path="inverse-probability-weighting-ipw.html"><a href="inverse-probability-weighting-ipw.html"><i class="fa fa-check"></i><b>7.7</b> Inverse Probability Weighting (IPW)</a></li>
<li class="chapter" data-level="7.8" data-path="comparing-ipw-with-aggregated-estimate.html"><a href="comparing-ipw-with-aggregated-estimate.html"><i class="fa fa-check"></i><b>7.8</b> Comparing IPW with Aggregated Estimate</a></li>
<li class="chapter" data-level="7.9" data-path="aipw-and-estimation.html"><a href="aipw-and-estimation.html"><i class="fa fa-check"></i><b>7.9</b> AIPW and Estimation</a></li>
<li class="chapter" data-level="7.10" data-path="assessing-balance.html"><a href="assessing-balance.html"><i class="fa fa-check"></i><b>7.10</b> Assessing Balance</a></li>
<li class="chapter" data-level="7.11" data-path="cross-fitting.html"><a href="cross-fitting.html"><i class="fa fa-check"></i><b>7.11</b> Cross-fitting</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="difference-in-differences.html"><a href="difference-in-differences.html"><i class="fa fa-check"></i><b>8</b> Difference in Differences</a>
<ul>
<li class="chapter" data-level="8.1" data-path="a-quick-introduction.html"><a href="a-quick-introduction.html"><i class="fa fa-check"></i><b>8.1</b> A Quick Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="set-up.html"><a href="set-up.html"><i class="fa fa-check"></i><b>8.2</b> Set up</a></li>
<li class="chapter" data-level="8.3" data-path="an-example-evaluating-the-impact-of-medicaid-expansion-on-uninsured-rate.html"><a href="an-example-evaluating-the-impact-of-medicaid-expansion-on-uninsured-rate.html"><i class="fa fa-check"></i><b>8.3</b> An example: Evaluating the impact of Medicaid expansion on uninsured rate</a></li>
<li class="chapter" data-level="8.4" data-path="naive-estimator.html"><a href="naive-estimator.html"><i class="fa fa-check"></i><b>8.4</b> Naive estimator</a></li>
<li class="chapter" data-level="8.5" data-path="canonical-difference-in-differences-framework.html"><a href="canonical-difference-in-differences-framework.html"><i class="fa fa-check"></i><b>8.5</b> Canonical Difference in Differences Framework</a></li>
<li class="chapter" data-level="8.6" data-path="did-in-multi-period-set-up.html"><a href="did-in-multi-period-set-up.html"><i class="fa fa-check"></i><b>8.6</b> DiD in multi-period set up</a></li>
<li class="chapter" data-level="8.7" data-path="conditional-parallel-trend-assumption.html"><a href="conditional-parallel-trend-assumption.html"><i class="fa fa-check"></i><b>8.7</b> Conditional Parallel Trend Assumption</a></li>
<li class="chapter" data-level="8.8" data-path="some-concerns-with-controls.html"><a href="some-concerns-with-controls.html"><i class="fa fa-check"></i><b>8.8</b> Some concerns with controls</a></li>
<li class="chapter" data-level="8.9" data-path="the-2-times-2-difference-in-differences-estimate.html"><a href="the-2-times-2-difference-in-differences-estimate.html"><i class="fa fa-check"></i><b>8.9</b> The <span class="math inline">\(2 \times 2\)</span> Difference-in-Differences Estimate</a></li>
<li class="chapter" data-level="8.10" data-path="event-study-model.html"><a href="event-study-model.html"><i class="fa fa-check"></i><b>8.10</b> Event study model</a></li>
<li class="chapter" data-level="8.11" data-path="two-way-fixed-effect-twfe-revisited.html"><a href="two-way-fixed-effect-twfe-revisited.html"><i class="fa fa-check"></i><b>8.11</b> Two way fixed effect (TWFE) Revisited</a></li>
<li class="chapter" data-level="8.12" data-path="various-ways-of-estimation.html"><a href="various-ways-of-estimation.html"><i class="fa fa-check"></i><b>8.12</b> Various ways of estimation</a></li>
<li class="chapter" data-level="8.13" data-path="multi-period-multi-group-and-variation-in-treatment-timing.html"><a href="multi-period-multi-group-and-variation-in-treatment-timing.html"><i class="fa fa-check"></i><b>8.13</b> Multi Period, Multi Group and Variation in Treatment Timing</a></li>
<li class="chapter" data-level="8.14" data-path="problem-with-twfe-in-multiple-group-with-treatment-timing-variation.html"><a href="problem-with-twfe-in-multiple-group-with-treatment-timing-variation.html"><i class="fa fa-check"></i><b>8.14</b> Problem with TWFE in Multiple Group with Treatment Timing Variation</a></li>
<li class="chapter" data-level="8.15" data-path="what-is-twfe-estimating-when-there-is-treatment-timing-variation.html"><a href="what-is-twfe-estimating-when-there-is-treatment-timing-variation.html"><i class="fa fa-check"></i><b>8.15</b> What is TWFE Estimating when there is Treatment Timing Variation?</a></li>
<li class="chapter" data-level="8.16" data-path="assumptions-governing-twfedd-estimate.html"><a href="assumptions-governing-twfedd-estimate.html"><i class="fa fa-check"></i><b>8.16</b> Assumptions governing TWFEDD estimate</a></li>
<li class="chapter" data-level="8.17" data-path="how-does-treatment-effect-heterogeneity-in-time-affect-twfe.html"><a href="how-does-treatment-effect-heterogeneity-in-time-affect-twfe.html"><i class="fa fa-check"></i><b>8.17</b> How Does Treatment Effect Heterogeneity in Time Affect TWFE?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="causal-forest.html"><a href="causal-forest.html"><i class="fa fa-check"></i><b>9</b> Causal Forest</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="summary-of-grf.html"><a href="summary-of-grf.html"><i class="fa fa-check"></i><b>9.2</b> Summary of GRF</a></li>
<li class="chapter" data-level="9.3" data-path="motivation-for-causal-forests.html"><a href="motivation-for-causal-forests.html"><i class="fa fa-check"></i><b>9.3</b> Motivation for Causal Forests</a></li>
<li class="chapter" data-level="9.4" data-path="causal-forest-1.html"><a href="causal-forest-1.html"><i class="fa fa-check"></i><b>9.4</b> Causal Forest</a></li>
<li class="chapter" data-level="9.5" data-path="an-example-of-causal-forest.html"><a href="an-example-of-causal-forest.html"><i class="fa fa-check"></i><b>9.5</b> An example of causal forest</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="heterogeneous-treatment-effects.html"><a href="heterogeneous-treatment-effects.html"><i class="fa fa-check"></i><b>10</b> Heterogeneous Treatment Effects</a>
<ul>
<li class="chapter" data-level="10.1" data-path="some-ways-to-estimate-cate.html"><a href="some-ways-to-estimate-cate.html"><i class="fa fa-check"></i><b>10.1</b> Some ways to estimate CATE</a></li>
<li class="chapter" data-level="10.2" data-path="estimation-1.html"><a href="estimation-1.html"><i class="fa fa-check"></i><b>10.2</b> Estimation</a></li>
<li class="chapter" data-level="10.3" data-path="some-remarks-and-questions.html"><a href="some-remarks-and-questions.html"><i class="fa fa-check"></i><b>10.3</b> Some Remarks and Questions</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation-of-propensity-score" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Estimation of propensity score<a href="estimation-of-propensity-score.html#estimation-of-propensity-score" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Propensity scores can be estimated using various statistical or machine learning models.</p></li>
<li><p>We will first estimate propensity score using a logistic regression model, where the treatment assignment <span class="math inline">\(W\)</span> is regressed on the covariates <span class="math inline">\(X\)</span>.</p></li>
<li><p>Next, we will estimate propensity score using random forest model built within the GRF framework in Athey et al. </p></li>
</ul>
<p><strong>Logistic Regression</strong></p>
<p>Using a linear regression framework to predict probabilities when the outcome is binary <span class="math inline">\(\{0, \; 1\}\)</span> falls short since the predicted values can go beyond 0 and 1. Many models contain
values within the range of 0 and 1, which can be used to model a binary response. The logistic regression uses a logistic function given as:</p>
<p><span class="math display" id="eq:logit">\[\begin{equation}
p(X) = \frac{e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + .... \beta_p X_p}}{1 + e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + .... \beta_p X_p}} \tag{7.9}  
\end{equation}\]</span></p>
<p>It is easy to see that <span class="math inline">\(lim_{a \rightarrow - \inf}[\frac{e^a}{1+e^a}] = 0\)</span> and <span class="math inline">\(lim_{a \rightarrow \inf}[\frac{e^a}{1+e^a}] = 1\)</span>. Equation @ref{eq:logit} can be transformed using the <em>logit transformation</em> given as:</p>
<p><span class="math display">\[\begin{equation}
g(X) = ln[\frac{p(X)}{1-p(X)}] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + .... \beta_p X_p
\end{equation}\]</span></p>
<p>We want to fit a logistic regression in order to predict the probability. For now, we will use simulated data.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="estimation-of-propensity-score.html#cb134-1" tabindex="-1"></a><span class="co"># helper packages</span></span>
<span id="cb134-2"><a href="estimation-of-propensity-score.html#cb134-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)  <span class="co"># data wrangling </span></span>
<span id="cb134-3"><a href="estimation-of-propensity-score.html#cb134-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2) <span class="co"># plots</span></span>
<span id="cb134-4"><a href="estimation-of-propensity-score.html#cb134-4" tabindex="-1"></a><span class="fu">library</span>(rsample) <span class="co"># data splitting</span></span>
<span id="cb134-5"><a href="estimation-of-propensity-score.html#cb134-5" tabindex="-1"></a><span class="fu">library</span>(tidyr) <span class="co"># for reshaping, pivot_wider</span></span>
<span id="cb134-6"><a href="estimation-of-propensity-score.html#cb134-6" tabindex="-1"></a></span>
<span id="cb134-7"><a href="estimation-of-propensity-score.html#cb134-7" tabindex="-1"></a><span class="co"># Modeling package </span></span>
<span id="cb134-8"><a href="estimation-of-propensity-score.html#cb134-8" tabindex="-1"></a><span class="fu">library</span>(caret) <span class="co"># for logistic regression modeling </span></span>
<span id="cb134-9"><a href="estimation-of-propensity-score.html#cb134-9" tabindex="-1"></a></span>
<span id="cb134-10"><a href="estimation-of-propensity-score.html#cb134-10" tabindex="-1"></a><span class="co"># Model interpretability </span></span>
<span id="cb134-11"><a href="estimation-of-propensity-score.html#cb134-11" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb134-12"><a href="estimation-of-propensity-score.html#cb134-12" tabindex="-1"></a></span>
<span id="cb134-13"><a href="estimation-of-propensity-score.html#cb134-13" tabindex="-1"></a></span>
<span id="cb134-14"><a href="estimation-of-propensity-score.html#cb134-14" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">194</span>) <span class="co"># for replicability</span></span>
<span id="cb134-15"><a href="estimation-of-propensity-score.html#cb134-15" tabindex="-1"></a></span>
<span id="cb134-16"><a href="estimation-of-propensity-score.html#cb134-16" tabindex="-1"></a><span class="co"># Generate simulated Data </span></span>
<span id="cb134-17"><a href="estimation-of-propensity-score.html#cb134-17" tabindex="-1"></a></span>
<span id="cb134-18"><a href="estimation-of-propensity-score.html#cb134-18" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2000</span> <span class="co"># number of obsevations</span></span>
<span id="cb134-19"><a href="estimation-of-propensity-score.html#cb134-19" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># number of covariates</span></span>
<span id="cb134-20"><a href="estimation-of-propensity-score.html#cb134-20" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p) <span class="co"># data matrix</span></span>
<span id="cb134-21"><a href="estimation-of-propensity-score.html#cb134-21" tabindex="-1"></a>true_effect  <span class="ot">&lt;-</span> <span class="fl">2.5</span></span>
<span id="cb134-22"><a href="estimation-of-propensity-score.html#cb134-22" tabindex="-1"></a></span>
<span id="cb134-23"><a href="estimation-of-propensity-score.html#cb134-23" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.1</span> <span class="sc">+</span> <span class="fl">0.4</span> <span class="sc">*</span> (X[, <span class="dv">1</span>] <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">+</span> <span class="fl">0.2</span> <span class="sc">*</span> (X[, <span class="dv">2</span>] <span class="sc">&gt;</span> <span class="dv">0</span>))</span>
<span id="cb134-24"><a href="estimation-of-propensity-score.html#cb134-24" tabindex="-1"></a>prob  <span class="ot">&lt;-</span> <span class="fl">0.1</span> <span class="sc">+</span> <span class="fl">0.4</span> <span class="sc">*</span> (X[, <span class="dv">1</span>] <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">+</span> <span class="fl">0.2</span> <span class="sc">*</span> (X[, <span class="dv">2</span>] <span class="sc">&gt;</span> <span class="dv">0</span>)  <span class="co"># oracle propensity score</span></span>
<span id="cb134-25"><a href="estimation-of-propensity-score.html#cb134-25" tabindex="-1"></a></span>
<span id="cb134-26"><a href="estimation-of-propensity-score.html#cb134-26" tabindex="-1"></a>Y <span class="ot">&lt;-</span> true_effect <span class="sc">*</span> W <span class="sc">+</span> X[, <span class="dv">2</span>] <span class="sc">+</span> <span class="fu">pmax</span>(X[, <span class="dv">1</span>], <span class="dv">0</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb134-27"><a href="estimation-of-propensity-score.html#cb134-27" tabindex="-1"></a><span class="co">#plot(X[, 1], X[, 2], col = as.factor(W))</span></span>
<span id="cb134-28"><a href="estimation-of-propensity-score.html#cb134-28" tabindex="-1"></a></span>
<span id="cb134-29"><a href="estimation-of-propensity-score.html#cb134-29" tabindex="-1"></a>dat  <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">cbind</span>(W, Y, X))</span>
<span id="cb134-30"><a href="estimation-of-propensity-score.html#cb134-30" tabindex="-1"></a><span class="fu">colnames</span>(dat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;W&quot;</span>, <span class="st">&quot;Y&quot;</span>, <span class="fu">paste0</span>(<span class="st">&quot;X&quot;</span>, <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>))) </span>
<span id="cb134-31"><a href="estimation-of-propensity-score.html#cb134-31" tabindex="-1"></a>dat  <span class="ot">&lt;-</span> dat  <span class="sc">%&gt;%</span> </span>
<span id="cb134-32"><a href="estimation-of-propensity-score.html#cb134-32" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">W =</span> <span class="fu">as.factor</span>(W))</span>
<span id="cb134-33"><a href="estimation-of-propensity-score.html#cb134-33" tabindex="-1"></a></span>
<span id="cb134-34"><a href="estimation-of-propensity-score.html#cb134-34" tabindex="-1"></a><span class="co"># create 70% training and 30% test data </span></span>
<span id="cb134-35"><a href="estimation-of-propensity-score.html#cb134-35" tabindex="-1"></a>churn_split  <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(dat, <span class="at">prop =</span> <span class="fl">0.7</span>)</span>
<span id="cb134-36"><a href="estimation-of-propensity-score.html#cb134-36" tabindex="-1"></a>dat_train  <span class="ot">&lt;-</span> <span class="fu">training</span>(churn_split)</span>
<span id="cb134-37"><a href="estimation-of-propensity-score.html#cb134-37" tabindex="-1"></a>dat_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(churn_split)</span>
<span id="cb134-38"><a href="estimation-of-propensity-score.html#cb134-38" tabindex="-1"></a></span>
<span id="cb134-39"><a href="estimation-of-propensity-score.html#cb134-39" tabindex="-1"></a><span class="co"># dimension of training and testing data</span></span>
<span id="cb134-40"><a href="estimation-of-propensity-score.html#cb134-40" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dim</span>(dat_train))</span></code></pre></div>
<pre><code>## [1] 1400   12</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="estimation-of-propensity-score.html#cb136-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dim</span>(dat_test))</span></code></pre></div>
<pre><code>## [1] 600  12</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="estimation-of-propensity-score.html#cb138-1" tabindex="-1"></a><span class="co"># let&#39;s compare two different models</span></span>
<span id="cb138-2"><a href="estimation-of-propensity-score.html#cb138-2" tabindex="-1"></a></span>
<span id="cb138-3"><a href="estimation-of-propensity-score.html#cb138-3" tabindex="-1"></a><span class="co"># using X1 as the predictor</span></span>
<span id="cb138-4"><a href="estimation-of-propensity-score.html#cb138-4" tabindex="-1"></a>cv_model1  <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb138-5"><a href="estimation-of-propensity-score.html#cb138-5" tabindex="-1"></a>     W <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, </span>
<span id="cb138-6"><a href="estimation-of-propensity-score.html#cb138-6" tabindex="-1"></a>    <span class="at">data =</span> dat_train, </span>
<span id="cb138-7"><a href="estimation-of-propensity-score.html#cb138-7" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb138-8"><a href="estimation-of-propensity-score.html#cb138-8" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>, </span>
<span id="cb138-9"><a href="estimation-of-propensity-score.html#cb138-9" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb138-10"><a href="estimation-of-propensity-score.html#cb138-10" tabindex="-1"></a>)</span>
<span id="cb138-11"><a href="estimation-of-propensity-score.html#cb138-11" tabindex="-1"></a></span>
<span id="cb138-12"><a href="estimation-of-propensity-score.html#cb138-12" tabindex="-1"></a><span class="co"># misses out on X1</span></span>
<span id="cb138-13"><a href="estimation-of-propensity-score.html#cb138-13" tabindex="-1"></a>cv_model2  <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb138-14"><a href="estimation-of-propensity-score.html#cb138-14" tabindex="-1"></a>     W <span class="sc">~</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, </span>
<span id="cb138-15"><a href="estimation-of-propensity-score.html#cb138-15" tabindex="-1"></a>    <span class="at">data =</span> dat_train, </span>
<span id="cb138-16"><a href="estimation-of-propensity-score.html#cb138-16" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb138-17"><a href="estimation-of-propensity-score.html#cb138-17" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>, </span>
<span id="cb138-18"><a href="estimation-of-propensity-score.html#cb138-18" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb138-19"><a href="estimation-of-propensity-score.html#cb138-19" tabindex="-1"></a>)</span>
<span id="cb138-20"><a href="estimation-of-propensity-score.html#cb138-20" tabindex="-1"></a></span>
<span id="cb138-21"><a href="estimation-of-propensity-score.html#cb138-21" tabindex="-1"></a></span>
<span id="cb138-22"><a href="estimation-of-propensity-score.html#cb138-22" tabindex="-1"></a><span class="co"># print the sample performance measures </span></span>
<span id="cb138-23"><a href="estimation-of-propensity-score.html#cb138-23" tabindex="-1"></a></span>
<span id="cb138-24"><a href="estimation-of-propensity-score.html#cb138-24" tabindex="-1"></a>sum_performance  <span class="ot">&lt;-</span>  <span class="fu">summary</span>(</span>
<span id="cb138-25"><a href="estimation-of-propensity-score.html#cb138-25" tabindex="-1"></a>    <span class="fu">resamples</span>(</span>
<span id="cb138-26"><a href="estimation-of-propensity-score.html#cb138-26" tabindex="-1"></a>        <span class="fu">list</span>(</span>
<span id="cb138-27"><a href="estimation-of-propensity-score.html#cb138-27" tabindex="-1"></a>            model1  <span class="ot">&lt;-</span> cv_model1, </span>
<span id="cb138-28"><a href="estimation-of-propensity-score.html#cb138-28" tabindex="-1"></a>            model2  <span class="ot">&lt;-</span> cv_model2</span>
<span id="cb138-29"><a href="estimation-of-propensity-score.html#cb138-29" tabindex="-1"></a>        )</span>
<span id="cb138-30"><a href="estimation-of-propensity-score.html#cb138-30" tabindex="-1"></a>    )</span>
<span id="cb138-31"><a href="estimation-of-propensity-score.html#cb138-31" tabindex="-1"></a>)</span>
<span id="cb138-32"><a href="estimation-of-propensity-score.html#cb138-32" tabindex="-1"></a></span>
<span id="cb138-33"><a href="estimation-of-propensity-score.html#cb138-33" tabindex="-1"></a>sum_performance<span class="sc">$</span>statistics<span class="sc">$</span>Accuracy</span></code></pre></div>
<pre><code>##             Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## Model1 0.6043165 0.6446429 0.6678571 0.6706292 0.6964286 0.7285714    0
## Model2 0.5642857 0.5785714 0.5892392 0.5935621 0.6160714 0.6285714    0</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="estimation-of-propensity-score.html#cb140-1" tabindex="-1"></a><span class="co"># use the confusion matrix </span></span>
<span id="cb140-2"><a href="estimation-of-propensity-score.html#cb140-2" tabindex="-1"></a></span>
<span id="cb140-3"><a href="estimation-of-propensity-score.html#cb140-3" tabindex="-1"></a><span class="co"># predict class </span></span>
<span id="cb140-4"><a href="estimation-of-propensity-score.html#cb140-4" tabindex="-1"></a></span>
<span id="cb140-5"><a href="estimation-of-propensity-score.html#cb140-5" tabindex="-1"></a>threshold  <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb140-6"><a href="estimation-of-propensity-score.html#cb140-6" tabindex="-1"></a>pred_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_model1, dat_train, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb140-7"><a href="estimation-of-propensity-score.html#cb140-7" tabindex="-1"></a>pred_class_manual  <span class="ot">&lt;-</span>  <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">1400</span>)</span>
<span id="cb140-8"><a href="estimation-of-propensity-score.html#cb140-8" tabindex="-1"></a>pred_class_manual[pred_prob[, <span class="dv">2</span>] <span class="sc">&gt;=</span> <span class="fl">0.5</span>]  <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb140-9"><a href="estimation-of-propensity-score.html#cb140-9" tabindex="-1"></a></span>
<span id="cb140-10"><a href="estimation-of-propensity-score.html#cb140-10" tabindex="-1"></a>pred_class  <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_model1, dat_train)</span>
<span id="cb140-11"><a href="estimation-of-propensity-score.html#cb140-11" tabindex="-1"></a></span>
<span id="cb140-12"><a href="estimation-of-propensity-score.html#cb140-12" tabindex="-1"></a><span class="co"># print the confusion matrix </span></span>
<span id="cb140-13"><a href="estimation-of-propensity-score.html#cb140-13" tabindex="-1"></a><span class="fu">confusionMatrix</span>(</span>
<span id="cb140-14"><a href="estimation-of-propensity-score.html#cb140-14" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">relevel</span>(pred_class, <span class="at">ref =</span> <span class="st">&quot;1&quot;</span>), <span class="co"># predictions</span></span>
<span id="cb140-15"><a href="estimation-of-propensity-score.html#cb140-15" tabindex="-1"></a>    <span class="at">reference =</span> <span class="fu">relevel</span>(dat_train<span class="sc">$</span>W, <span class="at">ref =</span> <span class="st">&quot;1&quot;</span>) <span class="co"># reference or the true value</span></span>
<span id="cb140-16"><a href="estimation-of-propensity-score.html#cb140-16" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   0
##          1 270 151
##          0 299 680
##                                          
##                Accuracy : 0.6786         
##                  95% CI : (0.6534, 0.703)
##     No Information Rate : 0.5936         
##     P-Value [Acc &gt; NIR] : 3.164e-11      
##                                          
##                   Kappa : 0.3053         
##                                          
##  Mcnemar&#39;s Test P-Value : 4.219e-12      
##                                          
##             Sensitivity : 0.4745         
##             Specificity : 0.8183         
##          Pos Pred Value : 0.6413         
##          Neg Pred Value : 0.6946         
##              Prevalence : 0.4064         
##          Detection Rate : 0.1929         
##    Detection Prevalence : 0.3007         
##       Balanced Accuracy : 0.6464         
##                                          
##        &#39;Positive&#39; Class : 1              
## </code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="estimation-of-propensity-score.html#cb142-1" tabindex="-1"></a><span class="co"># if predict all yes still get an accuracy of 0.5936</span></span>
<span id="cb142-2"><a href="estimation-of-propensity-score.html#cb142-2" tabindex="-1"></a><span class="fu">table</span>(dat_train<span class="sc">$</span>W)  <span class="sc">%&gt;%</span> <span class="fu">prop.table</span>()</span></code></pre></div>
<pre><code>## 
##         0         1 
## 0.5935714 0.4064286</code></pre>
<p>Looking at the confusion matrix, the values on the downward diagonal ([1, 1] and [2, 2] in matrix) are correctly idenfified by the model, while the upward diagonal values ([2, 1] and [1, 2]) are incorrectly classified. If all of the observations were assigned the value of 0, the accuracy would still be 0.5936%. This is termed as the <em>no information rate</em>. The model performs quite well in predicting True Negatives (classify as 0, when the value is actually 0). However, it does not perform so well in classifying the True Positives – more than 50% of the positive cases are classified as negative.</p>
<p>Next, two measures of importance are <em>sensitivity</em> and <em>specificity</em>. The sensitivity measure tracks the true positive rate from the model, while the specificity measure tracks the true negative rate.</p>
<ul>
<li><p><span class="math inline">\(sensitivity = \frac{True \; positives}{True \; positives + False \; negatives} = 0.8790\)</span>.</p></li>
<li><p><span class="math inline">\(specificity = \frac{True \; negatives}{True \; negatives \; + \; False \; positives} = \frac{604}{604 + 85} = 0.8766\)</span>.</p></li>
</ul>
<p><strong>How are the observations classified?</strong>
A threshold value is used to transform the raw prediction of probabilities into classification such that <span class="math inline">\(P(Y_{i} &gt; p_{threshold})=1.\)</span> The implicit <span class="math inline">\(p_{threshold}\)</span> used is 0.5. Varying the threshold from 0 to 1, one can calculate the relationship between the False Positive Rate (the prediction is positive when in actual the outcome is negative) and True Positive Rate at each threshold value. If the threshold value <span class="math inline">\((p_{threshold})\)</span> is 1, then all observations are classified as 0, which means that the False Positive Rate is 0 but so is the True Positive Rate. Similarly, if the threshold is 0, then both True and False positive rates are 1. This gives the Receiver Operating Characteristic (ROC).</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="estimation-of-propensity-score.html#cb144-1" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb144-2"><a href="estimation-of-propensity-score.html#cb144-2" tabindex="-1"></a></span>
<span id="cb144-3"><a href="estimation-of-propensity-score.html#cb144-3" tabindex="-1"></a><span class="co"># compute probabilities </span></span>
<span id="cb144-4"><a href="estimation-of-propensity-score.html#cb144-4" tabindex="-1"></a>m1_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_model1, dat_train, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="dv">2</span>]</span>
<span id="cb144-5"><a href="estimation-of-propensity-score.html#cb144-5" tabindex="-1"></a>m2_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_model2, dat_train, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="dv">2</span>]</span>
<span id="cb144-6"><a href="estimation-of-propensity-score.html#cb144-6" tabindex="-1"></a></span>
<span id="cb144-7"><a href="estimation-of-propensity-score.html#cb144-7" tabindex="-1"></a><span class="co"># AUC metrics </span></span>
<span id="cb144-8"><a href="estimation-of-propensity-score.html#cb144-8" tabindex="-1"></a>perf1  <span class="ot">&lt;-</span> <span class="fu">prediction</span>(m1_prob, dat_train<span class="sc">$</span>W)  <span class="sc">%&gt;%</span> </span>
<span id="cb144-9"><a href="estimation-of-propensity-score.html#cb144-9" tabindex="-1"></a>            <span class="fu">performance</span>(<span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)</span>
<span id="cb144-10"><a href="estimation-of-propensity-score.html#cb144-10" tabindex="-1"></a></span>
<span id="cb144-11"><a href="estimation-of-propensity-score.html#cb144-11" tabindex="-1"></a>perf2  <span class="ot">&lt;-</span> <span class="fu">prediction</span>(m2_prob, dat_train<span class="sc">$</span>W)  <span class="sc">%&gt;%</span> </span>
<span id="cb144-12"><a href="estimation-of-propensity-score.html#cb144-12" tabindex="-1"></a>            <span class="fu">performance</span>(<span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)</span>
<span id="cb144-13"><a href="estimation-of-propensity-score.html#cb144-13" tabindex="-1"></a></span>
<span id="cb144-14"><a href="estimation-of-propensity-score.html#cb144-14" tabindex="-1"></a><span class="co"># plot ROC curves</span></span>
<span id="cb144-15"><a href="estimation-of-propensity-score.html#cb144-15" tabindex="-1"></a><span class="fu">plot</span>(perf1, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb144-16"><a href="estimation-of-propensity-score.html#cb144-16" tabindex="-1"></a><span class="fu">plot</span>(perf2, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">&quot;green&quot;</span>) </span>
<span id="cb144-17"><a href="estimation-of-propensity-score.html#cb144-17" tabindex="-1"></a><span class="fu">legend</span>(<span class="fl">0.8</span>, <span class="fl">0.2</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;cv_model1&quot;</span>, <span class="st">&quot;cv_model2&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb144-18"><a href="estimation-of-propensity-score.html#cb144-18" tabindex="-1"></a>            <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>), <span class="at">cex =</span> <span class="fl">0.6</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-31"></span>
<img src="book_files/figure-html/unnamed-chunk-31-1.png" alt="ROC" width="672" />
<p class="caption">
Figure 7.1: ROC
</p>
</div>
<p>The figure above plots the ROC for two models that we tested using cross-validation. The cv_model2 produces a diagonal line, which means that this model is as good as a random guess. Next, cv_model1 performs a whole lot better since a large gains in True positive rate can be achieved with a relatively small increase in False positive rate at the start. The ROC curve pertaining to cv_model1 helps pick a threshold to balance the sensitivity (True Positive Rate) and specificity (1 - False Positive Rate).</p>
<p>The histogram of the estimated propensity scores using the logistic regression is as:</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="estimation-of-propensity-score.html#cb145-1" tabindex="-1"></a><span class="fu">hist</span>(pred_prob[, <span class="dv">2</span>], <span class="at">main =</span> <span class="st">&quot;Histogram of P(W=1|X)</span></span>
<span id="cb145-2"><a href="estimation-of-propensity-score.html#cb145-2" tabindex="-1"></a><span class="st">      </span><span class="sc">\n</span><span class="st"> using Logistic Regression&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;probabilities&quot;</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Now, let’s take a look at the confusion matrix using the test data.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="estimation-of-propensity-score.html#cb146-1" tabindex="-1"></a>pred_class_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_model1, dat_test)</span>
<span id="cb146-2"><a href="estimation-of-propensity-score.html#cb146-2" tabindex="-1"></a></span>
<span id="cb146-3"><a href="estimation-of-propensity-score.html#cb146-3" tabindex="-1"></a><span class="co"># print the confusion matrix this time for the test sample </span></span>
<span id="cb146-4"><a href="estimation-of-propensity-score.html#cb146-4" tabindex="-1"></a><span class="fu">confusionMatrix</span>(</span>
<span id="cb146-5"><a href="estimation-of-propensity-score.html#cb146-5" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">relevel</span>(pred_class_test, <span class="at">ref =</span> <span class="st">&quot;1&quot;</span>), <span class="co"># classification from the prediction</span></span>
<span id="cb146-6"><a href="estimation-of-propensity-score.html#cb146-6" tabindex="-1"></a>    <span class="at">reference =</span> <span class="fu">relevel</span>(dat_test<span class="sc">$</span>W, <span class="at">ref =</span> <span class="st">&quot;1&quot;</span>) <span class="co"># ground truth </span></span>
<span id="cb146-7"><a href="estimation-of-propensity-score.html#cb146-7" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   1   0
##          1  94  69
##          0 131 306
##                                           
##                Accuracy : 0.6667          
##                  95% CI : (0.6274, 0.7043)
##     No Information Rate : 0.625           
##     P-Value [Acc &gt; NIR] : 0.01882         
##                                           
##                   Kappa : 0.2474          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.608e-05       
##                                           
##             Sensitivity : 0.4178          
##             Specificity : 0.8160          
##          Pos Pred Value : 0.5767          
##          Neg Pred Value : 0.7002          
##              Prevalence : 0.3750          
##          Detection Rate : 0.1567          
##    Detection Prevalence : 0.2717          
##       Balanced Accuracy : 0.6169          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<p>The measures of accuracy, sensitivity, and specificity are similar for both the training and testing sample.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="propensity-score.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="using-cross-fitting-to-predict-propensity-score.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  },
  "toolbar": {
    "position": "static"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
